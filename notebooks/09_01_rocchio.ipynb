{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 09.01. Rocchio's Algorithm\n",
                "\n",
                "## Table of Contents\n",
                "1. [Introduction](#introduction)\n",
                "2. [Theory: Rocchio's Algorithm](#theory)\n",
                "3. [Implementation](#implementation)\n",
                "4. [Interactive Feedback Loop](#interactive)\n",
                "5. [Summary](#summary)\n",
                "\n",
                "---\n",
                "\n",
                "## 1. Introduction <a name=\"introduction\"></a>\n",
                "\n",
                "**Rocchio's Algorithm** is a classic relevance feedback method that improves query results by learning from user feedback.\n",
                "\n",
                "### The Process:\n",
                "1. User provides initial query\n",
                "2. System returns initial results\n",
                "3. **User marks** documents as relevant/non-relevant\n",
                "4. **System refines** query based on feedback\n",
                "5. Returns improved results\n",
                "\n",
                "### Key Idea:\n",
                "\n",
                "### Formula:\n",
                "$$\n",
                "\\vec{Q}_{new} = \\alpha \\vec{Q}_{old} + \\beta \\frac{1}{|D_r|} \\sum_{d \\in D_r} \\vec{d} - \\gamma \\frac{1}{|D_{nr}|} \\sum_{d \\in D_{nr}} \\vec{d}\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- $\\vec{Q}_{old}$ = Original query vector\n",
                "- $D_r$ = Set of relevant documents\n",
                "- $D_{nr}$ = Set of non-relevant documents\n",
                "- $\\alpha, \\beta, \\gamma$ = Weights (typically: Œ±=1, Œ≤=0.75, Œ≥=0.15)\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Theory:Rocchio's Algorithm <a name=\"theory\"></a>\n",
                "\n",
                "### Intuition:\n",
                "- **Move query** closer to relevant documents\n",
                "- **Move query** away from non-relevant documents\n",
                "- **Preserve** some of original query intent (Œ±)\n",
                "\n",
                "### Parameters:\n",
                "- **Œ± (alpha)**: Weight for original query (usually 1.0)\n",
                "- **Œ≤ (beta)**: Weight for relevant docs (usually 0.75)\n",
                "- **Œ≥ (gamma)**: Weight for non-relevant docs (usually 0.15)\n",
                "\n",
                "### Why it Works:\n",
                "- Relevant docs likely share common features\n",
                "- Non-relevant docs indicate what to avoid\n",
                "- Balance between exploration and exploitation\n",
                "\n",
                "---\n",
                "\n",
                "## 3. Implementation <a name=\"implementation\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Loaded 10 documents\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "from collections import Counter\n",
                "import math\n",
                "\n",
                "# Load data (same as previous notebooks)\n",
                "DATA_DIR = Path('../data')\n",
                "\n",
                "def load_documents(data_dir):\n",
                "    documents = {}\n",
                "    for file_path in sorted(data_dir.glob('doc*.txt')):\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            documents[file_path.stem] = f.read()\n",
                "    return documents\n",
                "\n",
                "def load_stopwords(file_path):\n",
                "    stopwords = set()\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            stopwords.add(line.strip())\n",
                "    return stopwords\n",
                "\n",
                "def load_stemming_dict(file_path):\n",
                "    stem_dict = {}\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            parts = line.strip().split(',')\n",
                "            if len(parts) == 2:\n",
                "                stem_dict[parts[0]] = parts[1]\n",
                "    return stem_dict\n",
                "\n",
                "def tokenize(text):\n",
                "    tokens = text.split()\n",
                "    cleaned = []\n",
                "    for token in tokens:\n",
                "        token = token.strip('‡•§,.!?;:\"\\'-()[]{}/')\n",
                "        if token and any('\\u0900' <= c <= '\\u097F' for c in token):\n",
                "            cleaned.append(token)\n",
                "    return cleaned\n",
                "\n",
                "def preprocess_text(text, stopwords, stem_dict):\n",
                "    tokens = tokenize(text)\n",
                "    tokens = [t for t in tokens if t not in stopwords]\n",
                "    tokens = [stem_dict.get(t, t) for t in tokens]\n",
                "    return tokens\n",
                "\n",
                "documents = load_documents(DATA_DIR)\n",
                "stopwords = load_stopwords(DATA_DIR / 'nepali_stopwords.csv')\n",
                "stem_dict = load_stemming_dict(DATA_DIR / 'nepali_stemming.csv')\n",
                "\n",
                "preprocessed_docs = {}\n",
                "for doc_id, text in documents.items():\n",
                "    preprocessed_docs[doc_id] = preprocess_text(text, stopwords, stem_dict)\n",
                "\n",
                "print(f\"‚úì Loaded {len(preprocessed_docs)} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Built 10 document vectors\n",
                        "  Vocabulary size: 398\n"
                    ]
                }
            ],
            "source": [
                "# Build vocabulary and TF vectors\n",
                "vocabulary = sorted(set(term for terms in preprocessed_docs.values() for term in terms))\n",
                "term_to_idx = {term: idx for idx, term in enumerate(vocabulary)}\n",
                "\n",
                "def build_tf_vector(terms, vocabulary, term_to_idx):\n",
                "    \"\"\"Build TF vector for a document.\"\"\"\n",
                "    vector = [0] * len(vocabulary)\n",
                "    term_counts = Counter(terms)\n",
                "    \n",
                "    for term, count in term_counts.items():\n",
                "        if term in term_to_idx:\n",
                "            vector[term_to_idx[term]] = count\n",
                "    \n",
                "    return vector\n",
                "\n",
                "# Build document vectors\n",
                "doc_vectors = {}\n",
                "for doc_id, terms in preprocessed_docs.items():\n",
                "    doc_vectors[doc_id] = build_tf_vector(terms, vocabulary, term_to_idx)\n",
                "\n",
                "print(f\"‚úì Built {len(doc_vectors)} document vectors\")\n",
                "print(f\"  Vocabulary size: {len(vocabulary)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Rocchio's algorithm functions defined\n"
                    ]
                }
            ],
            "source": [
                "def vector_add(v1, v2, weight=1.0):\n",
                "    \"\"\"Add two vectors with optional weight.\"\"\"\n",
                "    return [x + weight * y for x, y in zip(v1, v2)]\n",
                "\n",
                "def vector_scale(vector, scale):\n",
                "    \"\"\"Scale a vector by a constant.\"\"\"\n",
                "    return [scale * x for x in vector]\n",
                "\n",
                "def centroid(vectors):\n",
                "    \"\"\"Calculate centroid of multiple vectors.\"\"\"\n",
                "    if not vectors:\n",
                "        return [0] * len(vectors[0]) if vectors else []\n",
                "    \n",
                "    result = [0] * len(vectors[0])\n",
                "    for vec in vectors:\n",
                "        result = vector_add(result, vec)\n",
                "    \n",
                "    return vector_scale(result, 1.0 / len(vectors))\n",
                "\n",
                "def rocchio(query_vector, relevant_docs, non_relevant_docs, \n",
                "            alpha=1.0, beta=0.75, gamma=0.15):\n",
                "    \"\"\"\n",
                "    Rocchio's algorithm for query refinement.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    query_vector : list\n",
                "        Original query vector\n",
                "    relevant_docs : list of lists\n",
                "        Vectors of relevant documents\n",
                "    non_relevant_docs : list of lists\n",
                "        Vectors of non-relevant documents\n",
                "    alpha, beta, gamma : float\n",
                "        Rocchio parameters\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    list : Modified query vector\n",
                "    \"\"\"\n",
                "    # Start with weighted original query\n",
                "    new_query = vector_scale(query_vector, alpha)\n",
                "    \n",
                "    # Add relevant document centroid\n",
                "    if relevant_docs:\n",
                "        rel_centroid = centroid(relevant_docs)\n",
                "        new_query = vector_add(new_query, rel_centroid, beta)\n",
                "    \n",
                "    # Subtract non-relevant document centroid\n",
                "    if non_relevant_docs:\n",
                "        nonrel_centroid = centroid(non_relevant_docs)\n",
                "        new_query = vector_add(new_query, nonrel_centroid, -gamma)\n",
                "    \n",
                "    return new_query\n",
                "\n",
                "print(\"‚úì Rocchio's algorithm functions defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Interactive Feedback Loop <a name=\"interactive\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìö Rocchio's Algorithm - Relevance Feedback Example\n",
                        "======================================================================\n",
                        "\n",
                        "üîç Initial Query: '‡§®‡•á‡§™‡§æ‡§≤ ‡§π‡§ø‡§Æ‡§æ‡§≤'\n",
                        "   Terms: ['‡§®‡•á‡§™‡§æ‡§≤', '‡§π‡§ø‡§Æ‡§æ‡§≤']\n",
                        "\n",
                        "üìä Initial Results:\n",
                        "   1. doc02 (score: 0.6152)\n",
                        "   2. doc01 (score: 0.4698)\n",
                        "   3. doc09 (score: 0.4308)\n",
                        "   4. doc05 (score: 0.4045)\n",
                        "   5. doc04 (score: 0.3536)\n",
                        "\n",
                        "‚úì User Feedback:\n",
                        "   Relevant: ['doc02', 'doc01']\n",
                        "   Non-relevant: ['doc05']\n",
                        "\n",
                        "üìä Results After Rocchio:\n",
                        "   1. doc02 (score: 0.8139) ‚úì\n",
                        "   2. doc01 (score: 0.7570) ‚úì\n",
                        "   3. doc09 (score: 0.3401) \n",
                        "   4. doc06 (score: 0.3035) \n",
                        "   5. doc04 (score: 0.2799) \n",
                        "\n",
                        "üí° Relevant documents ranked higher after feedback!\n"
                    ]
                }
            ],
            "source": [
                "def cosine_similarity(v1, v2):\n",
                "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
                "    dot_prod = sum(x * y for x, y in zip(v1, v2))\n",
                "    mag1 = math.sqrt(sum(x ** 2 for x in v1))\n",
                "    mag2 = math.sqrt(sum(x ** 2 for x in v2))\n",
                "    \n",
                "    if mag1 == 0 or mag2 == 0:\n",
                "        return 0.0\n",
                "    \n",
                "    return dot_prod / (mag1 * mag2)\n",
                "\n",
                "def search(query_vector, doc_vectors, top_k=5):\n",
                "    \"\"\"Search documents using query vector.\"\"\"\n",
                "    scores = []\n",
                "    for doc_id, doc_vec in doc_vectors.items():\n",
                "        score = cosine_similarity(query_vector, doc_vec)\n",
                "        scores.append((doc_id, score))\n",
                "    \n",
                "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                "    return scores[:top_k]\n",
                "\n",
                "# Example: Relevance Feedback Iteration\n",
                "print(\"üìö Rocchio's Algorithm - Relevance Feedback Example\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Initial query\n",
                "query_text = \"‡§®‡•á‡§™‡§æ‡§≤ ‡§π‡§ø‡§Æ‡§æ‡§≤\"  \n",
                "query_terms = preprocess_text(query_text, stopwords, stem_dict)\n",
                "query_vector = build_tf_vector(query_terms, vocabulary, term_to_idx)\n",
                "\n",
                "print(f\"\\nüîç Initial Query: '{query_text}'\")\n",
                "print(f\"   Terms: {query_terms}\")\n",
                "\n",
                "# Initial search\n",
                "results = search(query_vector, doc_vectors, top_k=5)\n",
                "print(f\"\\nüìä Initial Results:\")\n",
                "for rank, (doc_id, score) in enumerate(results, 1):\n",
                "    title = documents[doc_id].split('\\n')[0] if documents[doc_id] else doc_id\n",
                "    print(f\"   {rank}. {doc_id} (score: {score:.4f})\")\n",
                "\n",
                "# Simulate user feedback\n",
                "# (In real implementation, user would mark these)\n",
                "relevant_doc_ids = [results[0][0], results[1][0]]  # Top 2 as relevant\n",
                "non_relevant_doc_ids = [results[3][0]]  # 4th as non-relevant\n",
                "\n",
                "print(f\"\\n‚úì User Feedback:\")\n",
                "print(f\"   Relevant: {relevant_doc_ids}\")\n",
                "print(f\"   Non-relevant: {non_relevant_doc_ids}\")\n",
                "\n",
                "# Apply Rocchio\n",
                "relevant_vecs = [doc_vectors[doc_id] for doc_id in relevant_doc_ids]\n",
                "non_relevant_vecs = [doc_vectors[doc_id] for doc_id in non_relevant_doc_ids]\n",
                "\n",
                "modified_query = rocchio(query_vector, relevant_vecs, non_relevant_vecs)\n",
                "\n",
                "# Search with modified query\n",
                "new_results = search(modified_query, doc_vectors, top_k=5)\n",
                "\n",
                "print(f\"\\nüìä Results After Rocchio:\")\n",
                "for rank, (doc_id, score) in enumerate(new_results, 1):\n",
                "    marker = \"‚úì\" if doc_id in relevant_doc_ids else \"\"\n",
                "    print(f\"   {rank}. {doc_id} (score: {score:.4f}) {marker}\")\n",
                "\n",
                "print(\"\\nüí° Relevant documents ranked higher after feedback!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Summary <a name=\"summary\"></a>\n",
                "\n",
                "### What We Learned:\n",
                "\n",
                "1. **Rocchio's Formula**\n",
                "   - Move query toward relevant docs\n",
                "   - Move query away from non-relevant docs\n",
                "   - Balance with original query intent\n",
                "\n",
                "2. **Parameters**\n",
                "   - Œ± = 1.0 (original query)\n",
                "   - Œ≤ = 0.75 (relevant docs)\n",
                "   - Œ≥ = 0.15 (non-relevant docs)\n",
                "\n",
                "3. **Implementation**\n",
                "   - Vector operations only\n",
                "   - Centroid calculation\n",
                "   - Iterative refinement\n",
                "\n",
                "### Benefits:\n",
                "- ‚úì Simple and effective\n",
                "- ‚úì Works with any vector model\n",
                "- ‚úì Improves recall and precision\n",
                "- ‚úì User-friendly interaction\n",
                "\n",
                "### Limitations:\n",
                "- Requires user feedback\n",
                "- May drift from original intent\n",
                "- Assumes relevant docs are similar\n",
                "- Query may become too long\n",
                "\n",
                "### Variations:\n",
                "- **Positive feedback only**: Set Œ≥ = 0\n",
                "- **Ide dec-hi**: Similar algorithm with different weights\n",
                "- **Probabilistic RF**: Use probability instead of vectors\n",
                "\n",
                "### Real-World Use:\n",
                "- Google \"Did you mean?\"\n",
                "- Amazon product recommendations\n",
                "- Email spam filters (marking spam helps)\n",
                "- Music recommendation systems\n",
                "\n",
                "### References:\n",
                "- Rocchio, J.J. (1971): \"Relevance feedback in information retrieval\"\n",
                "- Manning et al., Chapter 9.1\n",
                "- Salton & Buckley (1990): \"Improving retrieval performance by relevance feedback\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
