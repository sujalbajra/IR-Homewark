{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 10.01. Naive Bayes Classification with Feature Selection\n",
                "\n",
                "## Table of Contents\n",
                "1. [Introduction](#introduction)\n",
                "2. [Theory: Naive Bayes](#theory)\n",
                "3. [Feature Selection (Chi-Square)](#selection)\n",
                "4. [Training the Classifier](#training)\n",
                "5. [Classification](#classification)\n",
                "6. [Evaluation](#evaluation)\n",
                "7. [Summary](#summary)\n",
                "\n",
                "---\n",
                "\n",
                "## 1. Introduction <a name=\"introduction\"></a>\n",
                "\n",
                "**Naive Bayes** is a probabilistic classifier useful for categorizing documents.\n",
                "\n",
                "### Use Cases:\n",
                "- **Spam filtering**: Classify emails as spam/not spam\n",
                "- **Sentiment analysis**: Positive/negative reviews\n",
                "- **Topic classification**: Categorize news articles\n",
                "- **Language detection**: Identify document language\n",
                "\n",
                "### For Nepali IR:\n",
                "- Classify documents by topic (politics, sports, culture, etc.)\n",
                "- Filter content by category\n",
                "- Organize document collections\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Theory: Naive Bayes <a name=\"theory\"></a>\n",
                "\n",
                "### Bayes' Theorem:\n",
                "$$\n",
                "P(c|d) = \\frac{P(d|c) \\cdot P(c)}{P(d)}\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- $P(c|d)$ = Probability of class $c$ given document $d$\n",
                "- $P(d|c)$ = Probability of document given class (likelihood)\n",
                "- $P(c)$ = Prior probability of class\n",
                "- $P(d)$ = Probability of document (constant for all classes)\n",
                "\n",
                "### Classification Rule:\n",
                "$$\n",
                "c_{MAP} = \\arg\\max_c P(c) \\prod_{i=1}^{n} P(w_i|c)\n",
                "$$\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Loaded 60 documents\n",
                        "  Classes: {'politics', 'culture', 'tech', 'sports'}\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "from collections import Counter, defaultdict\n",
                "import math\n",
                "\n",
                "# Load data\n",
                "DATA_DIR = Path('../data')\n",
                "\n",
                "def load_documents(data_dir):\n",
                "    documents = {}\n",
                "    for file_path in sorted(data_dir.glob('doc*.txt')):\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            documents[file_path.stem] = f.read()\n",
                "    return documents\n",
                "\n",
                "def load_stopwords(file_path):\n",
                "    stopwords = set()\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            stopwords.add(line.strip())\n",
                "    return stopwords\n",
                "\n",
                "def load_stemming_dict(file_path):\n",
                "    stem_dict = {}\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            parts = line.strip().split(',')\n",
                "            if len(parts) == 2:\n",
                "                stem_dict[parts[0]] = parts[1]\n",
                "    return stem_dict\n",
                "\n",
                "def tokenize(text):\n",
                "    tokens = text.split()\n",
                "    cleaned = []\n",
                "    for token in tokens:\n",
                "        token = token.strip('।,.!?;:\"\\'-()[]{}/')\n",
                "        if token and any('\\u0900' <= c <= '\\u097F' for c in token):\n",
                "            cleaned.append(token)\n",
                "    return cleaned\n",
                "\n",
                "def preprocess_text(text, stopwords, stem_dict):\n",
                "    tokens = tokenize(text)\n",
                "    tokens = [t for t in tokens if t not in stopwords]\n",
                "    tokens = [stem_dict.get(t, t) for t in tokens]\n",
                "    return tokens\n",
                "\n",
                "documents = load_documents(DATA_DIR)\n",
                "stopwords = load_stopwords(DATA_DIR / 'nepali_stopwords.csv')\n",
                "stem_dict = load_stemming_dict(DATA_DIR / 'nepali_stemming.csv')\n",
                "\n",
                "# Use generated topics if available (from 00_data_expansion or manual tags)\n",
                "labels = {}\n",
                "for doc_id, text in documents.items():\n",
                "    # Simple heuristic for demo if labels missing\n",
                "    if 'politics' in doc_id: labels[doc_id] = 'politics'\n",
                "    elif 'sports' in doc_id: labels[doc_id] = 'sports'\n",
                "    elif 'tech' in doc_id: labels[doc_id] = 'tech'\n",
                "    elif 'doc001' <= doc_id <= 'doc003': labels[doc_id] = 'politics'\n",
                "    elif 'doc004' <= doc_id <= 'doc006': labels[doc_id] = 'sports'\n",
                "    else: labels[doc_id] = 'culture'\n",
                "\n",
                "preprocessed_docs = {}\n",
                "for doc_id, text in documents.items():\n",
                "    preprocessed_docs[doc_id] = preprocess_text(text, stopwords, stem_dict)\n",
                "\n",
                "print(f\"✓ Loaded {len(preprocessed_docs)} documents\")\n",
                "print(f\"  Classes: {set(labels.values())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Selection: Chi-Square ($\\chi^2$) <a name=\"selection\"></a>\n",
                "\n",
                "Not all words are useful for classification. Some adds noise. Feature selection picks the top-K terms that are most dependent on the class.\n",
                "\n",
                "We calculate the $\\chi^2$ statistic for each term $t$ and class $c$:\n",
                "\n",
                "$$ \\chi^2(t, c) = \\frac{N(N_{11}N_{00} - N_{10}N_{01})^2}{(N_{11} + N_{10})(N_{01} + N_{00})(N_{11} + N_{01})(N_{10} + N_{00})} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating Chi-Square for 470 terms...\n",
                        "✓ Selected 100 features\n",
                        "  Top 5: ['मोबाइल', 'सफ्टवेयर', 'संविधान', 'खेल', 'प्रतियोगिता']\n"
                    ]
                }
            ],
            "source": [
                "def chi_square_selection(docs, labels, top_k=50):\n",
                "    # 1. Compute Contingency Tables\n",
                "    # N11: doc has term, is in class\n",
                "    # N10: doc has term, not in class\n",
                "    # N01: doc no term, is in class\n",
                "    # N00: doc no term, not in class\n",
                "    \n",
                "    N = len(docs)\n",
                "    all_terms = set(w for d in docs.values() for w in d)\n",
                "    classes = set(labels.values())\n",
                "    \n",
                "    chi_scores = defaultdict(float)\n",
                "    \n",
                "    print(f\"Calculating Chi-Square for {len(all_terms)} terms...\")\n",
                "    \n",
                "    for term in all_terms:\n",
                "        term_score = 0\n",
                "        \n",
                "        for c in classes:\n",
                "            N11, N10, N01, N00 = 0, 0, 0, 0\n",
                "            \n",
                "            for doc_id, doc_terms in docs.items():\n",
                "                has_term = term in doc_terms\n",
                "                is_class = labels[doc_id] == c\n",
                "                \n",
                "                if has_term and is_class: N11 += 1\n",
                "                elif has_term and not is_class: N10 += 1\n",
                "                elif not has_term and is_class: N01 += 1\n",
                "                else: N00 += 1\n",
                "            \n",
                "            # Chi-square formula\n",
                "            numerator = N * (N11*N00 - N10*N01)**2\n",
                "            denominator = (N11 + N10) * (N01 + N00) * (N11 + N01) * (N10 + N00)\n",
                "            \n",
                "            if denominator > 0:\n",
                "                score = numerator / denominator\n",
                "                # Max score across classes (or avg)\n",
                "                term_score = max(term_score, score)\n",
                "        \n",
                "        chi_scores[term] = term_score\n",
                "        \n",
                "    # Select Top K\n",
                "    selected_features = sorted(chi_scores, key=chi_scores.get, reverse=True)[:top_k]\n",
                "    return selected_features, chi_scores\n",
                "\n",
                "# Select Top Features\n",
                "selected_features, scores = chi_square_selection(preprocessed_docs, labels, top_k=100)\n",
                "print(f\"✓ Selected {len(selected_features)} features\")\n",
                "print(f\"  Top 5: {selected_features[:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training with Selected Features <a name=\"training\"></a>\n",
                "We filter the vocabulary to only include selected features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Training complete (Vocab Size: 100)\n"
                    ]
                }
            ],
            "source": [
                "class NaiveBayesClassifier:\n",
                "    def __init__(self, vocabulary):\n",
                "        self.class_counts = Counter()\n",
                "        self.word_counts = defaultdict(Counter)\n",
                "        self.vocabulary = set(vocabulary)\n",
                "        self.total_docs = 0\n",
                "    \n",
                "    def train(self, documents, labels):\n",
                "        self.total_docs = len(documents)\n",
                "        \n",
                "        for doc_id, terms in documents.items():\n",
                "            cls = labels[doc_id]\n",
                "            self.class_counts[cls] += 1\n",
                "            \n",
                "            for term in terms:\n",
                "                if term in self.vocabulary: # ONLY use selected features\n",
                "                    self.word_counts[cls][term] += 1\n",
                "        \n",
                "        print(f\"✓ Training complete (Vocab Size: {len(self.vocabulary)})\")\n",
                "    \n",
                "    def predict(self, terms):\n",
                "        scores = {}\n",
                "        vocab_size = len(self.vocabulary)\n",
                "        \n",
                "        for cls in self.class_counts:\n",
                "            prior = math.log(self.class_counts[cls] / self.total_docs)\n",
                "            total_words = sum(self.word_counts[cls].values())\n",
                "            likelihood = 0\n",
                "            \n",
                "            for term in terms:\n",
                "                if term in self.vocabulary:\n",
                "                    word_count = self.word_counts[cls][term]\n",
                "                    prob = (word_count + 1) / (total_words + vocab_size)\n",
                "                    likelihood += math.log(prob)\n",
                "            \n",
                "            scores[cls] = prior + likelihood\n",
                "        \n",
                "        return max(scores, key=scores.get)\n",
                "\n",
                "# Train\n",
                "nb = NaiveBayesClassifier(selected_features)\n",
                "nb.train(preprocessed_docs, labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Summary <a name=\"summary\"></a>\n",
                "\n",
                "Feature selection:\n",
                "- ⬇️ Reduces model size\n",
                "- ⬇️ Removes noise\n",
                "- ⬆️ Can improve accuracy\n",
                "- ⬆️ Faster training"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
