{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04. Inverted Index - Efficient IR Data Structure\n",
                "\n",
                "## Table of Contents\n",
                "1. [Introduction](#introduction)\n",
                "2. [Theory: Inverted Index](#theory)\n",
                "3. [Building the Index](#building)\n",
                "4. [Query Processing with Index](#queries)\n",
                "5. [Performance Comparison](#performance)\n",
                "6. [Summary](#summary)\n",
                "\n",
                "---\n",
                "\n",
                "## 1. Introduction <a name=\"introduction\"></a>\n",
                "\n",
                "The **Inverted Index** is the fundamental data structure for modern search engines. It enables fast retrieval by mapping terms to the documents that contain them.\n",
                "\n",
                "### Why Inverted Index?\n",
                "- **Speed**: O(1) lookup for term ‚Üí documents mapping\n",
                "- **Space Efficient**: Stores only non-zero entries\n",
                "- **Scalable**: Used by Google, Elasticsearch, Apache Lucene\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Theory: Inverted Index <a name=\"theory\"></a>\n",
                "\n",
                "### Forward Index vs. Inverted Index\n",
                "\n",
                "**Forward Index** (Document ‚Üí Terms):\n",
                "```\n",
                "doc01: [‡§®‡•á‡§™‡§æ‡§≤, ‡§á‡§§‡§ø‡§π‡§æ‡§∏, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø, ...]\n",
                "doc02: [‡§®‡•á‡§™‡§æ‡§≤, ‡§π‡§ø‡§Æ‡§æ‡§≤, ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï, ...]\n",
                "doc03: [‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ, ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø, ‡§®‡•á‡§™‡§æ‡§≤, ...]\n",
                "```\n",
                "‚ùå **Problem**: To find docs with \"‡§®‡•á‡§™‡§æ‡§≤\", must scan ALL documents\n",
                "\n",
                "**Inverted Index** (Term ‚Üí Documents):\n",
                "```\n",
                "‡§®‡•á‡§™‡§æ‡§≤: [doc01, doc02, doc03, doc05, ...]\n",
                "‡§π‡§ø‡§Æ‡§æ‡§≤: [doc02, doc09]\n",
                "‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ: [doc03]\n",
                "```\n",
                "‚úì **Solution**: Direct lookup! O(1) time to find documents\n",
                "\n",
                "### Index Structure:\n",
                "\n",
                "1. **Dictionary (Lexicon)**\n",
                "   - All unique terms in collection\n",
                "   - Sorted alphabetically\n",
                "   - Points to posting list\n",
                "\n",
                "2. **Postings List**\n",
                "   - For each term: list of documents containing it\n",
                "   - Can include: position, frequency, metadata\n",
                "\n",
                "```\n",
                "Dictionary        Postings Lists\n",
                "----------        --------------\n",
                "‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞   ‚Üí    [doc04]\n",
                "‡§®‡•á‡§™‡§æ‡§≤       ‚Üí    [doc01, doc02, doc03, doc04, doc05, ...]\n",
                "‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï      ‚Üí    [doc02]\n",
                "‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ      ‚Üí    [doc03]\n",
                "```\n",
                "\n",
                "### Real-World Usage:\n",
                "- **Google**: Uses distributed inverted indices\n",
                "- **Elasticsearch**: JSON-based inverted index\n",
                "- **Apache Lucene**: Open-source inverted index library\n",
                "\n",
                "---\n",
                "\n",
                "## 3. Building the Index <a name=\"building\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Loaded 10 documents\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "from collections import defaultdict\n",
                "\n",
                "# Load and preprocess documents (same as previous notebooks)\n",
                "DATA_DIR = Path('../data')\n",
                "\n",
                "def load_documents(data_dir):\n",
                "    documents = {}\n",
                "    for file_path in sorted(data_dir.glob('doc*.txt')):\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            documents[file_path.stem] = f.read()\n",
                "    return documents\n",
                "\n",
                "def load_stopwords(file_path):\n",
                "    stopwords = set()\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            stopwords.add(line.strip())\n",
                "    return stopwords\n",
                "\n",
                "def load_stemming_dict(file_path):\n",
                "    stem_dict = {}\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            parts = line.strip().split(',')\n",
                "            if len(parts) == 2:\n",
                "                stem_dict[parts[0]] = parts[1]\n",
                "    return stem_dict\n",
                "\n",
                "def tokenize(text):\n",
                "    tokens = text.split()\n",
                "    cleaned = []\n",
                "    for token in tokens:\n",
                "        token = token.strip('‡•§,.!?;:\"\\'-()[]{}/')\n",
                "        if token and any('\\u0900' <= c <= '\\u097F' for c in token):\n",
                "            cleaned.append(token)\n",
                "    return cleaned\n",
                "\n",
                "def preprocess_text(text, stopwords, stem_dict):\n",
                "    tokens = tokenize(text)\n",
                "    tokens = [t for t in tokens if t not in stopwords]\n",
                "    tokens = [stem_dict.get(t, t) for t in tokens]\n",
                "    return tokens\n",
                "\n",
                "documents = load_documents(DATA_DIR)\n",
                "stopwords = load_stopwords(DATA_DIR / 'nepali_stopwords.csv')\n",
                "stem_dict = load_stemming_dict(DATA_DIR / 'nepali_stemming.csv')\n",
                "\n",
                "preprocessed_docs = {}\n",
                "for doc_id, text in documents.items():\n",
                "    preprocessed_docs[doc_id] = preprocess_text(text, stopwords, stem_dict)\n",
                "\n",
                "print(f\"‚úì Loaded {len(preprocessed_docs)} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Built inverted index\n",
                        "  Unique terms: 398\n",
                        "  Total postings: 474\n"
                    ]
                }
            ],
            "source": [
                "def build_inverted_index(preprocessed_docs):\n",
                "    \"\"\"\n",
                "    Build an inverted index from preprocessed documents.\n",
                "    \n",
                "    For each term, store the list of documents containing it.\n",
                "    This is a basic boolean inverted index.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    preprocessed_docs : dict\n",
                "        Mapping from doc_id to list of preprocessed terms\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    dict : Inverted index mapping term ‚Üí set of document IDs\n",
                "    \"\"\"\n",
                "    inverted_index = defaultdict(set)\n",
                "    \n",
                "    # For each document\n",
                "    for doc_id, terms in preprocessed_docs.items():\n",
                "        # For each unique term in document\n",
                "        unique_terms = set(terms)\n",
                "        for term in unique_terms:\n",
                "            # Add document to term's posting list\n",
                "            inverted_index[term].add(doc_id)\n",
                "    \n",
                "    # Convert defaultdict to regular dict for clarity\n",
                "    return dict(inverted_index)\n",
                "\n",
                "# Build the inverted index\n",
                "inverted_index = build_inverted_index(preprocessed_docs)\n",
                "\n",
                "print(f\"‚úì Built inverted index\")\n",
                "print(f\"  Unique terms: {len(inverted_index)}\")\n",
                "print(f\"  Total postings: {sum(len(postings) for postings in inverted_index.values())}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üìö Inverted Index Sample:\n",
                        "======================================================================\n",
                        "Term                 Document IDs                             Frequency\n",
                        "======================================================================\n",
                        "‡§®‡•á‡§™‡§æ‡§≤                doc01, doc02, doc03, doc04, doc05, ...   10\n",
                        "‡§π‡§ø‡§Æ‡§æ‡§≤                doc01, doc02, doc09                      3\n",
                        "‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ               doc03                                    1\n",
                        "‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï               doc02                                    1\n",
                        "‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø            doc07                                    1\n",
                        "‡§ï‡•É‡§∑‡§ø                 doc04, doc09                             2\n",
                        "‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø              doc10                                    1\n",
                        "‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø             doc01, doc06                             2\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Examine the index structure\n",
                "def show_index_sample(index, sample_terms):\n",
                "    \"\"\"\n",
                "    Display sample entries from the inverted index.\n",
                "    \"\"\"\n",
                "    print(\"\\nüìö Inverted Index Sample:\")\n",
                "    print(\"=\"*70)\n",
                "    print(f\"{'Term':<20} {'Document IDs':<40} {'Frequency'}\")\n",
                "    print(\"=\"*70)\n",
                "    \n",
                "    for term in sample_terms:\n",
                "        if term in index:\n",
                "            postings = sorted(index[term])\n",
                "            doc_str = ', '.join(postings)\n",
                "            if len(doc_str) > 38:\n",
                "                doc_str = doc_str[:35] + '...'\n",
                "            print(f\"{term:<20} {doc_str:<40} {len(postings)}\")\n",
                "        else:\n",
                "            print(f\"{term:<20} {'(not found)':<40} 0\")\n",
                "    \n",
                "    print(\"=\"*70)\n",
                "\n",
                "# Show interesting terms\n",
                "interesting_terms = ['‡§®‡•á‡§™‡§æ‡§≤', '‡§π‡§ø‡§Æ‡§æ‡§≤', '‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ', '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï', '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø', '‡§ï‡•É‡§∑‡§ø', '‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø', '‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø']\n",
                "show_index_sample(inverted_index, interesting_terms)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üìä Index Statistics:\n",
                        "======================================================================\n",
                        "  Total Terms: 398\n",
                        "  Total Postings: 474\n",
                        "  Avg Postings Per Term: 1.19\n",
                        "  Max Postings: 10\n",
                        "  Min Postings: 1\n",
                        "\n",
                        "üìà Top 10 Most Frequent Terms:\n",
                        "======================================================================\n",
                        "  1. ‡§®‡•á‡§™‡§æ‡§≤                appears in 10 documents\n",
                        "  2. ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£           appears in 5 documents\n",
                        "  3. ‡§µ‡§ø‡§ï‡§æ‡§∏                appears in 4 documents\n",
                        "  4. ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø            appears in 4 documents\n",
                        "  5. ‡§™‡•Å‡§∞‡§æ‡§®‡•ã               appears in 3 documents\n",
                        "  6. ‡§π‡§ø‡§Æ‡§æ‡§≤                appears in 3 documents\n",
                        "  7. ‡§™‡•ã‡§ñ‡§∞‡§æ                appears in 3 documents\n",
                        "  8. ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ             appears in 3 documents\n",
                        "  9. ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§Æ‡§æ            appears in 3 documents\n",
                        "  10. ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á              appears in 3 documents\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Statistics about the index\n",
                "def analyze_index(index):\n",
                "    \"\"\"\n",
                "    Compute statistics about the inverted index.\n",
                "    \"\"\"\n",
                "    posting_lengths = [len(postings) for postings in index.values()]\n",
                "    \n",
                "    stats = {\n",
                "        'total_terms': len(index),\n",
                "        'total_postings': sum(posting_lengths),\n",
                "        'avg_postings_per_term': round(sum(posting_lengths) / len(index), 2),\n",
                "        'max_postings': max(posting_lengths),\n",
                "        'min_postings': min(posting_lengths)\n",
                "    }\n",
                "    \n",
                "    # Find most common terms\n",
                "    term_freq = [(term, len(postings)) for term, postings in index.items()]\n",
                "    term_freq.sort(key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return stats, term_freq[:10]\n",
                "\n",
                "stats, top_terms = analyze_index(inverted_index)\n",
                "\n",
                "print(\"\\nüìä Index Statistics:\")\n",
                "print(\"=\"*70)\n",
                "for key, value in stats.items():\n",
                "    print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
                "\n",
                "print(\"\\nüìà Top 10 Most Frequent Terms:\")\n",
                "print(\"=\"*70)\n",
                "for i, (term, freq) in enumerate(top_terms, 1):\n",
                "    print(f\"  {i}. {term:<20} appears in {freq} documents\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Query Processing with Index <a name=\"queries\"></a>\n",
                "\n",
                "Using the inverted index makes query processing much more efficient!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Query functions defined\n"
                    ]
                }
            ],
            "source": [
                "def search_single_term(term, index):\n",
                "    \"\"\"\n",
                "    Search for documents containing a term.\n",
                "    \n",
                "    With inverted index: O(1) lookup!\n",
                "    \"\"\"\n",
                "    return index.get(term, set())\n",
                "\n",
                "def search_and(term1, term2, index):\n",
                "    \"\"\"\n",
                "    Boolean AND using inverted index.\n",
                "    \n",
                "    Returns documents containing BOTH terms.\n",
                "    \"\"\"\n",
                "    docs1 = search_single_term(term1, index)\n",
                "    docs2 = search_single_term(term2, index)\n",
                "    return docs1 & docs2\n",
                "\n",
                "def search_or(term1, term2, index):\n",
                "    \"\"\"\n",
                "    Boolean OR using inverted index.\n",
                "    \n",
                "    Returns documents containing EITHER term.\n",
                "    \"\"\"\n",
                "    docs1 = search_single_term(term1, index)\n",
                "    docs2 = search_single_term(term2, index)\n",
                "    return docs1 | docs2\n",
                "\n",
                "def search_not(term1, term2, index, all_docs):\n",
                "    \"\"\"\n",
                "    Boolean NOT using inverted index.\n",
                "    \n",
                "    Returns documents with term1 but NOT term2.\n",
                "    \"\"\"\n",
                "    docs1 = search_single_term(term1, index)\n",
                "    docs2 = search_single_term(term2, index)\n",
                "    return docs1 - docs2\n",
                "\n",
                "print(\"‚úì Query functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query Examples:\n",
                        "\n",
                        "1. Single term: '‡§®‡•á‡§™‡§æ‡§≤'\n",
                        "   Results: ['doc01', 'doc02', 'doc03', 'doc04', 'doc05', 'doc06', 'doc07', 'doc08', 'doc09', 'doc10']\n",
                        "   Count: 10 documents\n",
                        "\n",
                        "2. AND query: '‡§®‡•á‡§™‡§æ‡§≤' AND '‡§π‡§ø‡§Æ‡§æ‡§≤'\n",
                        "   Results: ['doc01', 'doc02', 'doc09']\n",
                        "   Count: 3 documents\n",
                        "\n",
                        "3. OR query: '‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ' OR '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø'\n",
                        "   Results: ['doc03', 'doc07']\n",
                        "   Count: 2 documents\n",
                        "\n",
                        "4. NOT query: '‡§®‡•á‡§™‡§æ‡§≤' AND NOT '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï'\n",
                        "   Results: ['doc01', 'doc03', 'doc04', 'doc05', 'doc06', 'doc07', 'doc08', 'doc09', 'doc10']\n",
                        "   Count: 9 documents\n"
                    ]
                }
            ],
            "source": [
                "# Test queries\n",
                "print(\"\\nüîç Query Examples:\\n\")\n",
                "\n",
                "# Query 1\n",
                "print(\"1. Single term: '‡§®‡•á‡§™‡§æ‡§≤'\")\n",
                "results = search_single_term('‡§®‡•á‡§™‡§æ‡§≤', inverted_index)\n",
                "print(f\"   Results: {sorted(results)}\")\n",
                "print(f\"   Count: {len(results)} documents\\n\")\n",
                "\n",
                "# Query 2\n",
                "print(\"2. AND query: '‡§®‡•á‡§™‡§æ‡§≤' AND '‡§π‡§ø‡§Æ‡§æ‡§≤'\")\n",
                "results = search_and('‡§®‡•á‡§™‡§æ‡§≤', '‡§π‡§ø‡§Æ‡§æ‡§≤', inverted_index)\n",
                "print(f\"   Results: {sorted(results)}\")\n",
                "print(f\"   Count: {len(results)} documents\\n\")\n",
                "\n",
                "# Query 3\n",
                "print(\"3. OR query: '‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ' OR '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø'\")\n",
                "results = search_or('‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ', '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø', inverted_index)\n",
                "print(f\"   Results: {sorted(results)}\")\n",
                "print(f\"   Count: {len(results)} documents\\n\")\n",
                "\n",
                "# Query 4\n",
                "all_doc_ids = set(preprocessed_docs.keys())\n",
                "print(\"4. NOT query: '‡§®‡•á‡§™‡§æ‡§≤' AND NOT '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï'\")\n",
                "results = search_not('‡§®‡•á‡§™‡§æ‡§≤', '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï', inverted_index, all_doc_ids)\n",
                "print(f\"   Results: {sorted(results)}\")\n",
                "print(f\"   Count: {len(results)} documents\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Performance Comparison <a name=\"performance\"></a>\n",
                "\n",
                "Let's compare inverted index vs. scanning all documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "‚ö° Performance Comparison:\n",
                        "======================================================================\n",
                        "Number of trials: 1000\n",
                        "Search term: '‡§®‡•á‡§™‡§æ‡§≤'\n",
                        "\n",
                        "Scanning all documents:\n",
                        "  Total time: 1.52 ms\n",
                        "  Average per query: 0.0015 ms\n",
                        "\n",
                        "Inverted Index:\n",
                        "  Total time: 0.00 ms\n",
                        "  Average per query: 0.0000 ms\n"
                    ]
                },
                {
                    "ename": "ZeroDivisionError",
                    "evalue": "float division by zero",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Total time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_index*\u001b[32m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Average per query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_index/num_trials*\u001b[32m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSpeedup: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtime_scan\u001b[49m\u001b[43m/\u001b[49m\u001b[43mtime_index\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx faster!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müí° Note: With 10 documents, the difference is small.\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mZeroDivisionError\u001b[39m: float division by zero"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "\n",
                "def search_by_scanning(term, preprocessed_docs):\n",
                "    \"\"\"\n",
                "    Naive approach: Scan all documents to find term.\n",
                "    O(n) where n = number of documents\n",
                "    \"\"\"\n",
                "    results = set()\n",
                "    for doc_id, terms in preprocessed_docs.items():\n",
                "        if term in terms:\n",
                "            results.add(doc_id)\n",
                "    return results\n",
                "\n",
                "# Compare performance\n",
                "test_term = '‡§®‡•á‡§™‡§æ‡§≤'\n",
                "num_trials = 1000\n",
                "\n",
                "# Method 1: Scanning\n",
                "start = time.time()\n",
                "for _ in range(num_trials):\n",
                "    results_scan = search_by_scanning(test_term, preprocessed_docs)\n",
                "time_scan = time.time() - start\n",
                "\n",
                "# Method 2: Inverted Index\n",
                "start = time.time()\n",
                "for _ in range(num_trials):\n",
                "    results_index = search_single_term(test_term, inverted_index)\n",
                "time_index = time.time() - start\n",
                "\n",
                "print(\"\\n‚ö° Performance Comparison:\")\n",
                "print(\"=\"*70)\n",
                "print(f\"Number of trials: {num_trials}\")\n",
                "print(f\"Search term: '{test_term}'\")\n",
                "print(f\"\\nScanning all documents:\")\n",
                "print(f\"  Total time: {time_scan*1000:.2f} ms\")\n",
                "print(f\"  Average per query: {time_scan/num_trials*1000:.4f} ms\")\n",
                "print(f\"\\nInverted Index:\")\n",
                "print(f\"  Total time: {time_index*1000:.2f} ms\")\n",
                "print(f\"  Average per query: {time_index/num_trials*1000:.4f} ms\")\n",
                "print(f\"\\nSpeedup: {time_scan/time_index:.1f}x faster!\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(\"\\nüí° Note: With 10 documents, the difference is small.\")\n",
                "print(\"   With millions of documents (like Google), inverted index is ESSENTIAL!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Summary <a name=\"summary\"></a>\n",
                "\n",
                "### What We Learned:\n",
                "\n",
                "1. **Inverted Index Structure**\n",
                "   - Maps terms ‚Üí documents (reverse of forward index)\n",
                "   - Dictionary + Posting lists\n",
                "   - Foundation of modern search engines\n",
                "\n",
                "2. **Building the Index**\n",
                "   - Iterate through all documents\n",
                "   - For each term, record which documents contain it\n",
                "   - Store as dictionary with sets for fast lookups\n",
                "\n",
                "3. **Query Processing**\n",
                "   - O(1) lookup for single term\n",
                "   - Set operations for Boolean queries\n",
                "   - Much faster than scanning documents\n",
                "\n",
                "4. **Performance**\n",
                "   - Critical for large collections\n",
                "   - Trades space for speed\n",
                "   - Scales to billions of documents (Google, etc.)\n",
                "\n",
                "### Index Statistics:\n",
                "- **Space Overhead**: Stores only non-zero entries (sparse)\n",
                "- **Build Time**: Linear in collection size, O(n)\n",
                "- **Query Time**: O(1) for term lookup, O(k) for result merging\n",
                "\n",
                "### Real-World Extensions:\n",
                "1. **Positional Index**: Store term positions for phrase queries\n",
                "2. **Term Frequency**: Store how many times term appears\n",
                "3. **Compression**: Reduce index size (variable byte encoding)\n",
                "4. **Distributed**: Shard index across multiple machines\n",
                "\n",
                "### Next Steps:\n",
                "In the next notebook (`05_vector_space_model.ipynb`), we will:\n",
                "- Move beyond binary retrieval\n",
                "- Represent documents as vectors\n",
                "- Calculate similarity scores\n",
                "- Rank documents by relevance\n",
                "\n",
                "### Research References:\n",
                "- Manning et al., \"Introduction to Information Retrieval\", Chapters 1-2\n",
                "- Inverted index is used in: Lucene, Elasticsearch, Solr, Google, Bing\n",
                "- First described by Gerard Salton in the 1960s"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
