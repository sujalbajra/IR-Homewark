{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03. Boolean Retrieval Model\n",
                "\n",
                "## Table of Contents\n",
                "1. [Introduction](#introduction)\n",
                "2. [Theory: Boolean Retrieval](#theory)\n",
                "3. [Document Term Matrix](#matrix)\n",
                "4. [Boolean Query Processing](#queries)\n",
                "5. [Query Examples](#examples)\n",
                "6. [Summary](#summary)\n",
                "\n",
                "---\n",
                "\n",
                "## 1. Introduction <a name=\"introduction\"></a>\n",
                "\n",
                "The **Boolean Retrieval Model** is one of the oldest and simplest IR models. It treats documents and queries as sets of terms and uses Boolean logic (AND, OR, NOT) to match documents.\n",
                "\n",
                "### Real-World Uses:\n",
                "- Library catalog systems\n",
                "- Legal document retrieval\n",
                "- Patent search\n",
                "- E-discovery systems\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Theory: Boolean Retrieval <a name=\"theory\"></a>\n",
                "\n",
                "### Binary Independence:\n",
                "- Documents either **match** or **don't match** a query\n",
                "- No concept of partial relevance or ranking\n",
                "- Each term is either **present (1)** or **absent (0)** in a document\n",
                "\n",
                "### Boolean Operators:\n",
                "\n",
                "1. **AND**: Both terms must be present\n",
                "   ```\n",
                "   Query: ‡§®‡•á‡§™‡§æ‡§≤ AND ‡§π‡§ø‡§Æ‡§æ‡§≤\n",
                "   Match: Documents containing BOTH terms\n",
                "   ```\n",
                "\n",
                "2. **OR**: At least one term must be present\n",
                "   ```\n",
                "   Query: ‡§®‡•á‡§™‡§æ‡§≤ OR ‡§≠‡§æ‡§∞‡§§\n",
                "   Match: Documents containing EITHER term\n",
                "   ```\n",
                "\n",
                "3. **NOT**: Term must be absent\n",
                "   ```\n",
                "   Query: ‡§®‡•á‡§™‡§æ‡§≤ AND NOT ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï\n",
                "   Match: Documents with ‡§®‡•á‡§™‡§æ‡§≤ but without ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï\n",
                "   ```\n",
                "\n",
                "### Document-Term Matrix:\n",
                "\n",
                "```\n",
                "          ‡§®‡•á‡§™‡§æ‡§≤  ‡§π‡§ø‡§Æ‡§æ‡§≤  ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ  ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï\n",
                "doc01      1      0      0       0\n",
                "doc02      1      1      0       1\n",
                "doc03      1      0      1       0\n",
                "doc04      0      0      0       0\n",
                "```\n",
                "\n",
                "### Advantages:\n",
                "- ‚úì Simple and fast\n",
                "- ‚úì Precise control over queries\n",
                "- ‚úì Reproducible results\n",
                "\n",
                "### Disadvantages:\n",
                "- ‚úó No ranking (all results equally relevant)\n",
                "- ‚úó Requires exact Boolean queries (hard for users)\n",
                "- ‚úó Feast or famine: Too many or too few results\n",
                "\n",
                "---\n",
                "\n",
                "## 3. Document-Term Matrix <a name=\"matrix\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Loaded and preprocessed 10 documents\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "from collections import defaultdict\n",
                "\n",
                "# Import preprocessing functions from previous notebook\n",
                "DATA_DIR = Path('../data')\n",
                "\n",
                "def load_documents(data_dir):\n",
                "    \"\"\"Load all documents.\"\"\"\n",
                "    documents = {}\n",
                "    for file_path in sorted(data_dir.glob('doc*.txt')):\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            documents[file_path.stem] = f.read()\n",
                "    return documents\n",
                "\n",
                "def load_stopwords(file_path):\n",
                "    \"\"\"Load stopwords from CSV.\"\"\"\n",
                "    stopwords = set()\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)  # Skip header\n",
                "        for line in f:\n",
                "            stopwords.add(line.strip())\n",
                "    return stopwords\n",
                "\n",
                "def load_stemming_dict(file_path):\n",
                "    \"\"\"Load stemming dictionary.\"\"\"\n",
                "    stem_dict = {}\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)  # Skip header\n",
                "        for line in f:\n",
                "            parts = line.strip().split(',')\n",
                "            if len(parts) == 2:\n",
                "                stem_dict[parts[0]] = parts[1]\n",
                "    return stem_dict\n",
                "\n",
                "def tokenize(text):\n",
                "    \"\"\"Tokenize text.\"\"\"\n",
                "    tokens = text.split()\n",
                "    cleaned = []\n",
                "    for token in tokens:\n",
                "        token = token.strip('‡•§,.!?;:\"\\'-()[]{}/')\n",
                "        if token and any('\\u0900' <= c <= '\\u097F' for c in token):\n",
                "            cleaned.append(token)\n",
                "    return cleaned\n",
                "\n",
                "def preprocess_text(text, stopwords, stem_dict):\n",
                "    \"\"\"Complete preprocessing pipeline.\"\"\"\n",
                "    tokens = tokenize(text)\n",
                "    tokens = [t for t in tokens if t not in stopwords]\n",
                "    tokens = [stem_dict.get(t, t) for t in tokens]\n",
                "    return tokens\n",
                "\n",
                "# Load resources\n",
                "documents = load_documents(DATA_DIR)\n",
                "stopwords = load_stopwords(DATA_DIR / 'nepali_stopwords.csv')\n",
                "stem_dict = load_stemming_dict(DATA_DIR / 'nepali_stemming.csv')\n",
                "\n",
                "# Preprocess all documents\n",
                "preprocessed_docs = {}\n",
                "for doc_id, text in documents.items():\n",
                "    preprocessed_docs[doc_id] = preprocess_text(text, stopwords, stem_dict)\n",
                "\n",
                "print(f\"‚úì Loaded and preprocessed {len(preprocessed_docs)} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Built document-term matrix\n",
                        "  Documents: 10\n",
                        "  Vocabulary size: 398\n",
                        "  Matrix size: 10 √ó 398 = 3980 cells\n"
                    ]
                }
            ],
            "source": [
                "def build_document_term_matrix(preprocessed_docs):\n",
                "    \"\"\"\n",
                "    Build a binary document-term matrix.\n",
                "    \n",
                "    Matrix[doc_id][term] = 1 if term in document, 0 otherwise\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    preprocessed_docs : dict\n",
                "        Mapping from doc_id to list of preprocessed terms\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    dict : Nested dictionary representing the matrix\n",
                "    set : Vocabulary (all unique terms)\n",
                "    \"\"\"\n",
                "    # Build vocabulary\n",
                "    vocabulary = set()\n",
                "    for terms in preprocessed_docs.values():\n",
                "        vocabulary.update(terms)\n",
                "    \n",
                "    # Build binary matrix\n",
                "    matrix = {}\n",
                "    for doc_id, terms in preprocessed_docs.items():\n",
                "        # Convert terms list to set for fast lookup\n",
                "        term_set = set(terms)\n",
                "        matrix[doc_id] = {}\n",
                "        \n",
                "        # For each term in vocabulary, check if present in document\n",
                "        for term in vocabulary:\n",
                "            matrix[doc_id][term] = 1 if term in term_set else 0\n",
                "    \n",
                "    return matrix, vocabulary\n",
                "\n",
                "# Build matrix\n",
                "doc_term_matrix, vocabulary = build_document_term_matrix(preprocessed_docs)\n",
                "\n",
                "print(f\"‚úì Built document-term matrix\")\n",
                "print(f\"  Documents: {len(doc_term_matrix)}\")\n",
                "print(f\"  Vocabulary size: {len(vocabulary)}\")\n",
                "print(f\"  Matrix size: {len(doc_term_matrix)} √ó {len(vocabulary)} = {len(doc_term_matrix) * len(vocabulary)} cells\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üìä Document-Term Matrix (sample):\n",
                        "================================================================================\n",
                        "Doc ID    ‡§®‡•á‡§™‡§æ‡§≤     ‡§π‡§ø‡§Æ‡§æ‡§≤     ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ    ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï    ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç  ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø   \n",
                        "================================================================================\n",
                        "doc01     1         1         0         0         0         0         \n",
                        "doc02     1         1         0         1         0         0         \n",
                        "doc03     1         0         1         0         0         0         \n",
                        "doc04     1         0         0         0         0         0         \n",
                        "doc05     1         0         0         0         0         0         \n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Visualize a small portion of the matrix\n",
                "def show_matrix_sample(matrix, vocabulary, sample_terms, sample_docs=None):\n",
                "    \"\"\"\n",
                "    Display a sample of the document-term matrix.\n",
                "    \"\"\"\n",
                "    if sample_docs is None:\n",
                "        sample_docs = sorted(matrix.keys())[:5]\n",
                "    \n",
                "    print(\"\\nüìä Document-Term Matrix (sample):\")\n",
                "    print(\"=\"*80)\n",
                "    \n",
                "    # Header\n",
                "    header = \"Doc ID    \"\n",
                "    for term in sample_terms:\n",
                "        header += f\"{term[:8]:<10}\"\n",
                "    print(header)\n",
                "    print(\"=\"*80)\n",
                "    \n",
                "    # Rows\n",
                "    for doc_id in sample_docs:\n",
                "        row = f\"{doc_id:<10}\"\n",
                "        for term in sample_terms:\n",
                "            value = matrix[doc_id].get(term, 0)\n",
                "            row += f\"{value:<10}\"\n",
                "        print(row)\n",
                "    \n",
                "    print(\"=\"*80)\n",
                "\n",
                "# Show sample with interesting terms\n",
                "interesting_terms = ['‡§®‡•á‡§™‡§æ‡§≤', '‡§π‡§ø‡§Æ‡§æ‡§≤', '‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ', '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï', '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø', '‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø']\n",
                "show_matrix_sample(doc_term_matrix, vocabulary, interesting_terms)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Boolean Query Processing <a name=\"queries\"></a>\n",
                "\n",
                "Now let's implement Boolean query processing with AND, OR, and NOT operators."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Boolean query functions defined\n"
                    ]
                }
            ],
            "source": [
                "def get_documents_containing_term(term, matrix):\n",
                "    \"\"\"\n",
                "    Get all documents containing a specific term.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    term : str\n",
                "        Search term\n",
                "    matrix : dict\n",
                "        Document-term matrix\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    set : Set of document IDs containing the term\n",
                "    \"\"\"\n",
                "    result = set()\n",
                "    for doc_id, terms in matrix.items():\n",
                "        if terms.get(term, 0) == 1:\n",
                "            result.add(doc_id)\n",
                "    return result\n",
                "\n",
                "def boolean_and(term1, term2, matrix):\n",
                "    \"\"\"\n",
                "    Boolean AND: Documents containing BOTH terms.\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    set : Intersection of documents containing term1 and term2\n",
                "    \"\"\"\n",
                "    docs1 = get_documents_containing_term(term1, matrix)\n",
                "    docs2 = get_documents_containing_term(term2, matrix)\n",
                "    return docs1 & docs2  # Set intersection\n",
                "\n",
                "def boolean_or(term1, term2, matrix):\n",
                "    \"\"\"\n",
                "    Boolean OR: Documents containing EITHER term.\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    set : Union of documents containing term1 or term2\n",
                "    \"\"\"\n",
                "    docs1 = get_documents_containing_term(term1, matrix)\n",
                "    docs2 = get_documents_containing_term(term2, matrix)\n",
                "    return docs1 | docs2  # Set union\n",
                "\n",
                "def boolean_not(term1, term2, matrix):\n",
                "    \"\"\"\n",
                "    Boolean NOT: Documents containing term1 but NOT term2.\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    set : Documents with term1 minus documents with term2\n",
                "    \"\"\"\n",
                "    docs1 = get_documents_containing_term(term1, matrix)\n",
                "    docs2 = get_documents_containing_term(term2, matrix)\n",
                "    return docs1 - docs2  # Set difference\n",
                "\n",
                "print(\"‚úì Boolean query functions defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Query Examples <a name=\"examples\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query 1: Documents containing '‡§®‡•á‡§™‡§æ‡§≤'\n",
                        "======================================================================\n",
                        "Results: ['doc01', 'doc02', 'doc03', 'doc04', 'doc05', 'doc06', 'doc07', 'doc08', 'doc09', 'doc10']\n",
                        "Number of documents: 10\n"
                    ]
                }
            ],
            "source": [
                "# Example 1: Single term query\n",
                "print(\"\\nüîç Query 1: Documents containing '‡§®‡•á‡§™‡§æ‡§≤'\")\n",
                "print(\"=\"*70)\n",
                "results = get_documents_containing_term('‡§®‡•á‡§™‡§æ‡§≤', doc_term_matrix)\n",
                "print(f\"Results: {sorted(results)}\")\n",
                "print(f\"Number of documents: {len(results)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query 2: '‡§®‡•á‡§™‡§æ‡§≤' AND '‡§π‡§ø‡§Æ‡§æ‡§≤'\n",
                        "======================================================================\n",
                        "Results: ['doc01', 'doc02', 'doc09']\n",
                        "Number of documents: 3\n",
                        "\n",
                        "üìÑ Sample from matching document:\n",
                        "\n",
                        "doc01:\n",
                        "‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø\n",
                        "\n",
                        "‡§®‡•á‡§™‡§æ‡§≤ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§è‡§∂‡§ø‡§Ø‡§æ‡§Æ‡§æ ‡§Ö‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§è‡§â‡§ü‡§æ ‡§∏‡•Å‡§®‡•ç‡§¶‡§∞ ‡§π‡§ø‡§Æ‡§æ‡§≤‡•Ä ‡§¶‡•á‡§∂ ‡§π‡•ã‡•§ ‡§Ø‡•ã ‡§¶‡•á‡§∂ ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∏‡§Æ‡•É‡§¶‡•ç‡§ß ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∞ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§µ‡§ø‡§∂‡•ç‡§µ‡§≠‡§∞ ‡§™‡•ç‡§∞‡§∏‡§ø‡§¶‡•ç‡§ß ‡§õ‡•§ ‡§®‡•á‡§™‡§æ‡§≤‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ú‡§æ‡§§‡§ú‡§æ‡§§‡§ø ‡§∞ ‡§ß‡§∞‡•ç‡§Æ‡§ï‡§æ ‡§Æ‡§æ‡§®‡§ø‡§∏‡§π‡§∞‡•Ç ‡§∏‡§¶‡•ç‡§≠...\n"
                    ]
                }
            ],
            "source": [
                "# Example 2: AND query\n",
                "print(\"\\nüîç Query 2: '‡§®‡•á‡§™‡§æ‡§≤' AND '‡§π‡§ø‡§Æ‡§æ‡§≤'\")\n",
                "print(\"=\"*70)\n",
                "results = boolean_and('‡§®‡•á‡§™‡§æ‡§≤', '‡§π‡§ø‡§Æ‡§æ‡§≤', doc_term_matrix)\n",
                "print(f\"Results: {sorted(results)}\")\n",
                "print(f\"Number of documents: {len(results)}\")\n",
                "\n",
                "# Show context from matching documents\n",
                "if results:\n",
                "    print(\"\\nüìÑ Sample from matching document:\")\n",
                "    sample_doc = sorted(results)[0]\n",
                "    print(f\"\\n{sample_doc}:\")\n",
                "    print(documents[sample_doc][:200] + \"...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query 3: '‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ' OR '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø'\n",
                        "======================================================================\n",
                        "Results: ['doc03', 'doc07']\n",
                        "Number of documents: 2\n"
                    ]
                }
            ],
            "source": [
                "# Example 3: OR query\n",
                "print(\"\\nüîç Query 3: '‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ' OR '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø'\")\n",
                "print(\"=\"*70)\n",
                "results = boolean_or('‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ', '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø', doc_term_matrix)\n",
                "print(f\"Results: {sorted(results)}\")\n",
                "print(f\"Number of documents: {len(results)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query 4: '‡§®‡•á‡§™‡§æ‡§≤' AND NOT '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï'\n",
                        "======================================================================\n",
                        "Results: ['doc01', 'doc03', 'doc04', 'doc05', 'doc06', 'doc07', 'doc08', 'doc09', 'doc10']\n",
                        "Number of documents: 9\n",
                        "\n",
                        "Interpretation: Documents about Nepal but not about tourism\n"
                    ]
                }
            ],
            "source": [
                "# Example 4: NOT query\n",
                "print(\"\\nüîç Query 4: '‡§®‡•á‡§™‡§æ‡§≤' AND NOT '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï'\")\n",
                "print(\"=\"*70)\n",
                "results = boolean_not('‡§®‡•á‡§™‡§æ‡§≤', '‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï', doc_term_matrix)\n",
                "print(f\"Results: {sorted(results)}\")\n",
                "print(f\"Number of documents: {len(results)}\")\n",
                "print(\"\\nInterpretation: Documents about Nepal but not about tourism\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query 5: (‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ OR ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø) AND ‡§®‡•á‡§™‡§æ‡§≤\n",
                        "======================================================================\n",
                        "Results: ['doc03']\n",
                        "Number of documents: 1\n",
                        "\n",
                        "Interpretation: Documents about education or technology in Nepal\n"
                    ]
                }
            ],
            "source": [
                "# Example 5: Complex query\n",
                "def complex_boolean_query(matrix):\n",
                "    \"\"\"\n",
                "    Example: (‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ OR ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø) AND ‡§®‡•á‡§™‡§æ‡§≤\n",
                "    \n",
                "    Find documents about education OR technology in Nepal.\n",
                "    \"\"\"\n",
                "    # Step 1: ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ OR ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø\n",
                "    education_or_tech = boolean_or('‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ', '‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø', matrix)\n",
                "    \n",
                "    # Step 2: Result AND ‡§®‡•á‡§™‡§æ‡§≤\n",
                "    nepal_docs = get_documents_containing_term('‡§®‡•á‡§™‡§æ‡§≤', matrix)\n",
                "    final_result = education_or_tech & nepal_docs\n",
                "    \n",
                "    return final_result\n",
                "\n",
                "print(\"\\nüîç Query 5: (‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ OR ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø) AND ‡§®‡•á‡§™‡§æ‡§≤\")\n",
                "print(\"=\"*70)\n",
                "results = complex_boolean_query(doc_term_matrix)\n",
                "print(f\"Results: {sorted(results)}\")\n",
                "print(f\"Number of documents: {len(results)}\")\n",
                "print(\"\\nInterpretation: Documents about education or technology in Nepal\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Summary <a name=\"summary\"></a>\n",
                "\n",
                "### What We Learned:\n",
                "\n",
                "1. **Boolean Retrieval Model**\n",
                "   - Binary representation: Term present (1) or absent (0)\n",
                "   - No ranking: Documents either match or don't match\n",
                "   - Used in library systems, legal search, patents\n",
                "\n",
                "2. **Document-Term Matrix**\n",
                "   - Binary matrix representation of documents\n",
                "   - Rows = documents, Columns = terms\n",
                "   - Foundation for retrieval operations\n",
                "\n",
                "3. **Boolean Operators**\n",
                "   - **AND**: Intersection (both terms)\n",
                "   - **OR**: Union (either term)\n",
                "   - **NOT**: Difference (exclude term)\n",
                "   - Implemented using set operations\n",
                "\n",
                "4. **Query Processing**\n",
                "   - Convert query to set operations\n",
                "   - Combine results using Boolean logic\n",
                "   - Support complex queries with multiple operators\n",
                "\n",
                "### Limitations:\n",
                "- **No ranking**: Can't distinguish more relevant documents\n",
                "- **Binary**: Ignores term frequency and importance\n",
                "- **User burden**: Requires understanding Boolean logic\n",
                "- **All or nothing**: Too many or too few results\n",
                "\n",
                "### Next Steps:\n",
                "In the next notebook (`04_inverted_index.ipynb`), we will:\n",
                "- Build an efficient inverted index structure\n",
                "- Optimize Boolean query processing\n",
                "- Implement posting lists\n",
                "- Compare performance with matrix approach\n",
                "\n",
                "### Research References:\n",
                "- Manning et al., \"Introduction to Information Retrieval\", Chapter 1\n",
                "- Boolean retrieval is the foundation of modern IR\n",
                "- Real systems use ranked retrieval (covered in later notebooks)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
