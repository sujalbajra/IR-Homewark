{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 06. TF-IDF Ranking\n",
                "\n",
                "## Table of Contents\n",
                "1. [Introduction](#introduction)\n",
                "2. [Theory: TF-IDF](#theory)\n",
                "3. [Computing TF-IDF](#computing)\n",
                "4. [TF-IDF Retrieval](#retrieval)\n",
                "5. [Comparison with TF](#comparison)\n",
                "6. [Summary](#summary)\n",
                "\n",
                "---\n",
                "\n",
                "## 1. Introduction <a name=\"introduction\"></a>\n",
                "\n",
                "**TF-IDF** (Term Frequency - Inverse Document Frequency) is the most important term weighting scheme in Information Retrieval.\n",
                "\n",
                "### The Problem:\n",
                "Simple term frequency treats all words equally. But:\n",
                "- **Common words** (‡§¶‡•á‡§∂, ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞) appear in many documents ‚Üí Less distinctive\n",
                "- **Rare words** (‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ, ‡§π‡§ø‡§Æ‡§æ‡§≤) appear in few documents ‚Üí More distinctive\n",
                "\n",
                "**TF-IDF Solution:** Give higher weight to rare, discriminative terms!\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Theory: TF-IDF <a name=\"theory\"></a>\n",
                "\n",
                "### Formula:\n",
                "\n",
                "$$\n",
                "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
                "$$\n",
                "\n",
                "### 1. Term Frequency (TF):\n",
                "How often term $t$ appears in document $d$.\n",
                "\n",
                "$$\n",
                "\\text{TF}(t, d) = \\text{count of } t \\text{ in } d\n",
                "$$\n",
                "\n",
                "**Variants:**\n",
                "- Raw count: $\\text{freq}(t, d)$\n",
                "- Log normalization: $1 + \\log(\\text{freq}(t, d))$ ‚Üê We'll use this\n",
                "- Boolean: $1$ if present, $0$ otherwise\n",
                "\n",
                "### 2. Inverse Document Frequency (IDF):\n",
                "How rare the term is across all documents.\n",
                "\n",
                "$$\n",
                "\\text{IDF}(t) = \\log\\left(\\frac{N}{\\text{df}(t)}\\right)\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- $N$ = Total number of documents\n",
                "- $\\text{df}(t)$ = Number of documents containing term $t$\n",
                "\n",
                "### Intuition:\n",
                "\n",
                "```\n",
                "Term: \"‡§®‡•á‡§™‡§æ‡§≤\"  ‚Üí appears in 8/10 docs ‚Üí IDF = log(10/8) = 0.22 (low)\n",
                "Term: \"‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ\" ‚Üí appears in 1/10 docs ‚Üí IDF = log(10/1) = 2.30 (high)\n",
                "```\n",
                "\n",
                "**Result:** Rare terms get higher weights!\n",
                "\n",
                "### Why Logarithm?\n",
                "- **Smoothing**: Prevents extreme values\n",
                "- **Diminishing returns**: Frequency 10‚Üí20 less important than 1‚Üí2\n",
                "- **Empirically proven**: Works best in practice\n",
                "\n",
                "---\n",
                "\n",
                "## 3. Computing TF-IDF <a name=\"computing\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Loaded 10 documents\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "from collections import Counter\n",
                "import math\n",
                "\n",
                "# Load data\n",
                "DATA_DIR = Path('../data')\n",
                "\n",
                "def load_documents(data_dir):\n",
                "    documents = {}\n",
                "    for file_path in sorted(data_dir.glob('doc*.txt')):\n",
                "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                "            documents[file_path.stem] = f.read()\n",
                "    return documents\n",
                "\n",
                "def load_stopwords(file_path):\n",
                "    stopwords = set()\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            stopwords.add(line.strip())\n",
                "    return stopwords\n",
                "\n",
                "def load_stemming_dict(file_path):\n",
                "    stem_dict = {}\n",
                "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "        next(f)\n",
                "        for line in f:\n",
                "            parts = line.strip().split(',')\n",
                "            if len(parts) == 2:\n",
                "                stem_dict[parts[0]] = parts[1]\n",
                "    return stem_dict\n",
                "\n",
                "def tokenize(text):\n",
                "    tokens = text.split()\n",
                "    cleaned = []\n",
                "    for token in tokens:\n",
                "        token = token.strip('‡•§,.!?;:\"\\'-()[]{}/')\n",
                "        if token and any('\\u0900' <= c <= '\\u097F' for c in token):\n",
                "            cleaned.append(token)\n",
                "    return cleaned\n",
                "\n",
                "def preprocess_text(text, stopwords, stem_dict):\n",
                "    tokens = tokenize(text)\n",
                "    tokens = [t for t in tokens if t not in stopwords]\n",
                "    tokens = [stem_dict.get(t, t) for t in tokens]\n",
                "    return tokens\n",
                "\n",
                "documents = load_documents(DATA_DIR)\n",
                "stopwords = load_stopwords(DATA_DIR / 'nepali_stopwords.csv')\n",
                "stem_dict = load_stemming_dict(DATA_DIR / 'nepali_stemming.csv')\n",
                "\n",
                "preprocessed_docs = {}\n",
                "for doc_id, text in documents.items():\n",
                "    preprocessed_docs[doc_id] = preprocess_text(text, stopwords, stem_dict)\n",
                "\n",
                "print(f\"‚úì Loaded {len(preprocessed_docs)} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Computed IDF for 398 terms\n"
                    ]
                }
            ],
            "source": [
                "def compute_document_frequency(preprocessed_docs):\n",
                "    \"\"\"\n",
                "    Compute document frequency for each term.\n",
                "    \n",
                "    DF(term) = number of documents containing the term\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    dict : term ‚Üí document frequency\n",
                "    \"\"\"\n",
                "    df = {}\n",
                "    \n",
                "    for terms in preprocessed_docs.values():\n",
                "        # Get unique terms in this document\n",
                "        unique_terms = set(terms)\n",
                "        \n",
                "        # Increment DF for each unique term\n",
                "        for term in unique_terms:\n",
                "            df[term] = df.get(term, 0) + 1\n",
                "    \n",
                "    return df\n",
                "\n",
                "def compute_idf(df, num_documents):\n",
                "    \"\"\"\n",
                "    Compute IDF for each term.\n",
                "    \n",
                "    IDF(term) = log(N / DF(term))\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    df : dict\n",
                "        Document frequency for each term\n",
                "    num_documents : int\n",
                "        Total number of documents\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    dict : term ‚Üí IDF value\n",
                "    \"\"\"\n",
                "    idf = {}\n",
                "    \n",
                "    for term, doc_freq in df.items():\n",
                "        # IDF = log(N / df)\n",
                "        idf[term] = math.log(num_documents / doc_freq)\n",
                "    \n",
                "    return idf\n",
                "\n",
                "# Compute DF and IDF\n",
                "df = compute_document_frequency(preprocessed_docs)\n",
                "idf = compute_idf(df, len(preprocessed_docs))\n",
                "\n",
                "print(f\"‚úì Computed IDF for {len(idf)} terms\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üìä IDF Values (High = Rare, Low = Common):\n",
                        "================================================================================\n",
                        "Term                 DF (# docs)     IDF Value       Category\n",
                        "================================================================================\n",
                        "\n",
                        "üîπ Rare Terms (High IDF):\n",
                        "‡§µ‡§ø‡§∂‡•ç‡§µ‡§≠‡§∞              1               2.3026          Very distinctive\n",
                        "‡§®‡•á‡§™‡§æ‡§≤‡§≤‡§æ‡§à             1               2.3026          Very distinctive\n",
                        "‡§ö‡§æ‡§°‡§™‡§∞‡•ç‡§µ‡§π‡§∞‡•Ç           1               2.3026          Very distinctive\n",
                        "‡§∂‡§æ‡§π‡§≤‡•á                1               2.3026          Very distinctive\n",
                        "‡•ß‡•≠‡•¨‡•Æ                 1               2.3026          Very distinctive\n",
                        "\n",
                        "üî∏ Common Terms (Low IDF):\n",
                        "‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ               3               1.2040          Less distinctive\n",
                        "‡§µ‡§ø‡§ï‡§æ‡§∏                4               0.9163          Less distinctive\n",
                        "‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø            4               0.9163          Less distinctive\n",
                        "‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£           5               0.6931          Less distinctive\n",
                        "‡§®‡•á‡§™‡§æ‡§≤                10              0.0000          Less distinctive\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Examine IDF values\n",
                "def show_idf_examples(idf, df, num_docs):\n",
                "    \"\"\"\n",
                "    Display IDF values for terms with different rarities.\n",
                "    \"\"\"\n",
                "    # Sort terms by IDF (high to low)\n",
                "    sorted_terms = sorted(idf.items(), key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    print(\"\\nüìä IDF Values (High = Rare, Low = Common):\")\n",
                "    print(\"=\"*80)\n",
                "    print(f\"{'Term':<20} {'DF (# docs)':<15} {'IDF Value':<15} {'Category'}\")\n",
                "    print(\"=\"*80)\n",
                "    \n",
                "    # Show top 5 (rarest)\n",
                "    print(\"\\nüîπ Rare Terms (High IDF):\")\n",
                "    for term, idf_val in sorted_terms[:5]:\n",
                "        doc_freq = df[term]\n",
                "        print(f\"{term:<20} {doc_freq:<15} {idf_val:<15.4f} Very distinctive\")\n",
                "    \n",
                "    # Show bottom 5 (most common)\n",
                "    print(\"\\nüî∏ Common Terms (Low IDF):\")\n",
                "    for term, idf_val in sorted_terms[-5:]:\n",
                "        doc_freq = df[term]\n",
                "        print(f\"{term:<20} {doc_freq:<15} {idf_val:<15.4f} Less distinctive\")\n",
                "    \n",
                "    print(\"=\"*80)\n",
                "\n",
                "show_idf_examples(idf, df, len(preprocessed_docs))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "‚úì Built TF-IDF vectors\n",
                        "  Vocabulary size: 398\n",
                        "  Number of vectors: 10\n"
                    ]
                }
            ],
            "source": [
                "def compute_tf_log_normalized(term_freq):\n",
                "    \"\"\"\n",
                "    Compute log-normalized TF.\n",
                "    \n",
                "    TF = 1 + log(freq) if freq > 0, else 0\n",
                "    \"\"\"\n",
                "    if term_freq == 0:\n",
                "        return 0\n",
                "    return 1 + math.log(term_freq)\n",
                "\n",
                "def build_tfidf_vectors(preprocessed_docs, vocabulary, idf):\n",
                "    \"\"\"\n",
                "    Build TF-IDF weighted document vectors.\n",
                "    \n",
                "    For each document and term:\n",
                "    weight = (1 + log(TF)) √ó IDF\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    preprocessed_docs : dict\n",
                "        Document ID ‚Üí list of terms\n",
                "    vocabulary : list\n",
                "        Sorted list of all unique terms\n",
                "    idf : dict\n",
                "        Term ‚Üí IDF value\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    dict : Document ID ‚Üí TF-IDF vector\n",
                "    \"\"\"\n",
                "    vectors = {}\n",
                "    term_to_idx = {term: idx for idx, term in enumerate(vocabulary)}\n",
                "    \n",
                "    for doc_id, terms in preprocessed_docs.items():\n",
                "        # Count term frequencies\n",
                "        term_counts = Counter(terms)\n",
                "        \n",
                "        # Build TF-IDF vector\n",
                "        vector = [0.0] * len(vocabulary)\n",
                "        \n",
                "        for term, freq in term_counts.items():\n",
                "            idx = term_to_idx[term]\n",
                "            \n",
                "            # TF component (log normalized)\n",
                "            tf = compute_tf_log_normalized(freq)\n",
                "            \n",
                "            # TF-IDF = TF √ó IDF\n",
                "            tfidf = tf * idf[term]\n",
                "            \n",
                "            vector[idx] = tfidf\n",
                "        \n",
                "        vectors[doc_id] = vector\n",
                "    \n",
                "    return vectors\n",
                "\n",
                "# Build vocabulary and TF-IDF vectors\n",
                "vocabulary = sorted(set(term for terms in preprocessed_docs.values() for term in terms))\n",
                "tfidf_vectors = build_tfidf_vectors(preprocessed_docs, vocabulary, idf)\n",
                "\n",
                "print(f\"\\n‚úì Built TF-IDF vectors\")\n",
                "print(f\"  Vocabulary size: {len(vocabulary)}\")\n",
                "print(f\"  Number of vectors: {len(tfidf_vectors)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üìÑ Document: doc02\n",
                        "Title: ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§®\n",
                        "================================================================================\n",
                        "Term            TF       TF(log)    IDF        TF-IDF\n",
                        "================================================================================\n",
                        "‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï          4        2.386      2.303      5.495\n",
                        "‡§Ü‡§â‡§Å‡§õ‡§®‡•ç          2        1.693      2.303      3.899\n",
                        "‡§∏‡•ç‡§§‡•Ç‡§™           2        1.693      2.303      3.899\n",
                        "‡§π‡§ø‡§Æ‡§æ‡§≤           5        2.609      1.204      3.142\n",
                        "‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡•ã         1        1.000      2.303      2.303\n",
                        "‡§Ö‡§ó‡•ç‡§≤‡•ã           1        1.000      2.303      2.303\n",
                        "‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ‡§ï‡•ã       1        1.000      2.303      2.303\n",
                        "‡§â‡§ö‡§æ‡§á            1        1.000      2.303      2.303\n",
                        "‡•Æ,‡•Æ‡•™‡•Æ.‡•Æ‡•¨        1        1.000      2.303      2.303\n",
                        "‡§Æ‡§ø‡§ü‡§∞            1        1.000      2.303      2.303\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Compare TF vs TF-IDF weights for a sample document\n",
                "def compare_tf_tfidf(doc_id, preprocessed_docs, vocabulary, idf, num_terms=10):\n",
                "    \"\"\"\n",
                "    Compare TF and TF-IDF weights for terms in a document.\n",
                "    \"\"\"\n",
                "    terms = preprocessed_docs[doc_id]\n",
                "    term_counts = Counter(terms)\n",
                "    \n",
                "    # Compute weights\n",
                "    weights = []\n",
                "    for term, freq in term_counts.items():\n",
                "        tf = freq\n",
                "        tf_log = compute_tf_log_normalized(freq)\n",
                "        tfidf = tf_log * idf[term]\n",
                "        weights.append((term, tf, tf_log, idf[term], tfidf))\n",
                "    \n",
                "    # Sort by TF-IDF (descending)\n",
                "    weights.sort(key=lambda x: x[4], reverse=True)\n",
                "    \n",
                "    print(f\"\\nüìÑ Document: {doc_id}\")\n",
                "    print(f\"Title: {documents[doc_id].split(chr(10))[0]}\")\n",
                "    print(\"=\"*80)\n",
                "    print(f\"{'Term':<15} {'TF':<8} {'TF(log)':<10} {'IDF':<10} {'TF-IDF'}\")\n",
                "    print(\"=\"*80)\n",
                "    \n",
                "    for term, tf, tf_log, idf_val, tfidf in weights[:num_terms]:\n",
                "        print(f\"{term:<15} {tf:<8} {tf_log:<10.3f} {idf_val:<10.3f} {tfidf:.3f}\")\n",
                "    \n",
                "    print(\"=\"*80)\n",
                "\n",
                "# Example for doc02 (about Himalayas and tourism)\n",
                "compare_tf_tfidf('doc02', preprocessed_docs, vocabulary, idf)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. TF-IDF Retrieval <a name=\"retrieval\"></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì TF-IDF retrieval functions defined\n"
                    ]
                }
            ],
            "source": [
                "def dot_product(vec1, vec2):\n",
                "    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
                "\n",
                "def vector_magnitude(vec):\n",
                "    return math.sqrt(sum(v ** 2 for v in vec))\n",
                "\n",
                "def cosine_similarity(vec1, vec2):\n",
                "    dot_prod = dot_product(vec1, vec2)\n",
                "    mag1 = vector_magnitude(vec1)\n",
                "    mag2 = vector_magnitude(vec2)\n",
                "    \n",
                "    if mag1 == 0 or mag2 == 0:\n",
                "        return 0.0\n",
                "    \n",
                "    return dot_prod / (mag1 * mag2)\n",
                "\n",
                "def query_to_tfidf_vector(query_text, vocabulary, stopwords, stem_dict, idf):\n",
                "    \"\"\"\n",
                "    Convert query to TF-IDF vector.\n",
                "    \"\"\"\n",
                "    # Preprocess query\n",
                "    query_terms = preprocess_text(query_text, stopwords, stem_dict)\n",
                "    term_counts = Counter(query_terms)\n",
                "    \n",
                "    # Build TF-IDF vector\n",
                "    term_to_idx = {term: idx for idx, term in enumerate(vocabulary)}\n",
                "    vector = [0.0] * len(vocabulary)\n",
                "    \n",
                "    for term, freq in term_counts.items():\n",
                "        if term in term_to_idx:\n",
                "            idx = term_to_idx[term]\n",
                "            tf = compute_tf_log_normalized(freq)\n",
                "            tfidf = tf * idf.get(term, 0)\n",
                "            vector[idx] = tfidf\n",
                "    \n",
                "    return vector\n",
                "\n",
                "def tfidf_ranked_retrieval(query_text, tfidf_vectors, vocabulary, stopwords, stem_dict, idf, top_k=5):\n",
                "    \"\"\"\n",
                "    Retrieve and rank documents using TF-IDF weighting.\n",
                "    \"\"\"\n",
                "    # Convert query to TF-IDF vector\n",
                "    query_vector = query_to_tfidf_vector(query_text, vocabulary, stopwords, stem_dict, idf)\n",
                "    \n",
                "    # Calculate similarity scores\n",
                "    scores = []\n",
                "    for doc_id, doc_vector in tfidf_vectors.items():\n",
                "        score = cosine_similarity(query_vector, doc_vector)\n",
                "        scores.append((doc_id, score))\n",
                "    \n",
                "    # Sort by score (descending)\n",
                "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return scores[:top_k]\n",
                "\n",
                "print(\"‚úì TF-IDF retrieval functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query: '‡§®‡•á‡§™‡§æ‡§≤ ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ'\n",
                        "======================================================================\n",
                        "\n",
                        "Rank   Doc ID     Score      Title\n",
                        "======================================================================\n",
                        "1      doc02      0.1942    ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§®\n",
                        "2      doc09      0.1404    ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§∞ ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å\n",
                        "3      doc01      0.0436    ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø\n",
                        "4      doc03      0.0000    ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§∞ ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø\n",
                        "5      doc04      0.0000    ‡§ï‡•É‡§∑‡§ø ‡§∞ ‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Test Query 1\n",
                "query1 = \"‡§®‡•á‡§™‡§æ‡§≤ ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ\"\n",
                "print(f\"\\nüîç Query: '{query1}'\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "results = tfidf_ranked_retrieval(query1, tfidf_vectors, vocabulary, stopwords, stem_dict, idf, top_k=5)\n",
                "\n",
                "print(f\"\\n{'Rank':<6} {'Doc ID':<10} {'Score':<10} {'Title'}\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "for rank, (doc_id, score) in enumerate(results, 1):\n",
                "    title = documents[doc_id].split('\\n')[0]\n",
                "    print(f\"{rank:<6} {doc_id:<10} {score:.4f}    {title}\")\n",
                "\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Query: '‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤'\n",
                        "======================================================================\n",
                        "\n",
                        "Rank   Doc ID     Score      Title\n",
                        "======================================================================\n",
                        "1      doc03      0.4482    ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§∞ ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø\n",
                        "2      doc07      0.0498    ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ\n",
                        "3      doc08      0.0460    ‡§Ø‡§æ‡§§‡§æ‡§Ø‡§æ‡§§ ‡§∞ ‡§∏‡§û‡•ç‡§ö‡§æ‡§∞\n",
                        "4      doc01      0.0000    ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø\n",
                        "5      doc02      0.0000    ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§®\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Test Query 2\n",
                "query2 = \"‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø ‡§°‡§ø‡§ú‡§ø‡§ü‡§≤\"\n",
                "print(f\"\\nüîç Query: '{query2}'\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "results = tfidf_ranked_retrieval(query2, tfidf_vectors, vocabulary, stopwords, stem_dict, idf, top_k=5)\n",
                "\n",
                "print(f\"\\n{'Rank':<6} {'Doc ID':<10} {'Score':<10} {'Title'}\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "for rank, (doc_id, score) in enumerate(results, 1):\n",
                "    title = documents[doc_id].split('\\n')[0]\n",
                "    print(f\"{rank:<6} {doc_id:<10} {score:.4f}    {title}\")\n",
                "\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Comparison with TF <a name=\"comparison\"></a>\n",
                "\n",
                "Let's compare TF-only vs TF-IDF ranking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üîç Comparison Query: '‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§ö‡§ø‡§§‡•Å‡§µ‡§æ'\n",
                        "\n",
                        "This query contains rare terms that should be weighted heavily.\n",
                        "\n",
                        "======================================================================\n",
                        "\n",
                        "üìä TF-only Ranking:\n",
                        "  1. doc02 (0.3418) - ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§®\n",
                        "  2. doc09 (0.1846) - ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§∞ ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å\n",
                        "  3. doc01 (0.0671) - ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø\n",
                        "  4. doc03 (0.0000) - ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§∞ ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø\n",
                        "  5. doc04 (0.0000) - ‡§ï‡•É‡§∑‡§ø ‡§∞ ‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞\n",
                        "\n",
                        "üìä TF-IDF Ranking:\n",
                        "  1. doc09 (0.1670) - ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§∞ ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å\n",
                        "  2. doc02 (0.0892) - ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§®\n",
                        "  3. doc01 (0.0338) - ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø\n",
                        "  4. doc03 (0.0000) - ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§∞ ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø\n",
                        "  5. doc04 (0.0000) - ‡§ï‡•É‡§∑‡§ø ‡§∞ ‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞\n",
                        "======================================================================\n",
                        "\n",
                        "üí° TF-IDF gives higher weight to rare, discriminative terms!\n"
                    ]
                }
            ],
            "source": [
                "# Build simple TF vectors for comparison\n",
                "def build_tf_vectors(preprocessed_docs, vocabulary):\n",
                "    \"\"\"Build vectors with raw term frequency.\"\"\"\n",
                "    vectors = {}\n",
                "    term_to_idx = {term: idx for idx, term in enumerate(vocabulary)}\n",
                "    \n",
                "    for doc_id, terms in preprocessed_docs.items():\n",
                "        term_counts = Counter(terms)\n",
                "        vector = [0] * len(vocabulary)\n",
                "        \n",
                "        for term, count in term_counts.items():\n",
                "            idx = term_to_idx[term]\n",
                "            vector[idx] = count\n",
                "        \n",
                "        vectors[doc_id] = vector\n",
                "    \n",
                "    return vectors\n",
                "\n",
                "tf_vectors = build_tf_vectors(preprocessed_docs, vocabulary)\n",
                "\n",
                "def tf_ranked_retrieval(query_text, tf_vectors, vocabulary, stopwords, stem_dict, top_k=5):\n",
                "    \"\"\"Retrieve using simple TF weighting.\"\"\"\n",
                "    query_terms = preprocess_text(query_text, stopwords, stem_dict)\n",
                "    term_counts = Counter(query_terms)\n",
                "    \n",
                "    term_to_idx = {term: idx for idx, term in enumerate(vocabulary)}\n",
                "    query_vector = [0] * len(vocabulary)\n",
                "    \n",
                "    for term, count in term_counts.items():\n",
                "        if term in term_to_idx:\n",
                "            query_vector[term_to_idx[term]] = count\n",
                "    \n",
                "    scores = []\n",
                "    for doc_id, doc_vector in tf_vectors.items():\n",
                "        score = cosine_similarity(query_vector, doc_vector)\n",
                "        scores.append((doc_id, score))\n",
                "    \n",
                "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                "    return scores[:top_k]\n",
                "\n",
                "# Compare on the same query\n",
                "query = \"‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§π‡§ø‡§Æ‡§æ‡§≤ ‡§ö‡§ø‡§§‡•Å‡§µ‡§æ\"\n",
                "\n",
                "print(f\"\\nüîç Comparison Query: '{query}'\")\n",
                "print(\"\\nThis query contains rare terms that should be weighted heavily.\\n\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# TF-only results\n",
                "print(\"\\nüìä TF-only Ranking:\")\n",
                "tf_results = tf_ranked_retrieval(query, tf_vectors, vocabulary, stopwords, stem_dict, top_k=5)\n",
                "for rank, (doc_id, score) in enumerate(tf_results, 1):\n",
                "    title = documents[doc_id].split('\\n')[0]\n",
                "    print(f\"  {rank}. {doc_id} ({score:.4f}) - {title}\")\n",
                "\n",
                "# TF-IDF results\n",
                "print(\"\\nüìä TF-IDF Ranking:\")\n",
                "tfidf_results = tfidf_ranked_retrieval(query, tfidf_vectors, vocabulary, stopwords, stem_dict, idf, top_k=5)\n",
                "for rank, (doc_id, score) in enumerate(tfidf_results, 1):\n",
                "    title = documents[doc_id].split('\\n')[0]\n",
                "    print(f\"  {rank}. {doc_id} ({score:.4f}) - {title}\")\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\\nüí° TF-IDF gives higher weight to rare, discriminative terms!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Summary <a name=\"summary\"></a>\n",
                "\n",
                "### What We Learned:\n",
                "\n",
                "1. **TF-IDF Formula**\n",
                "   - Combines term frequency and inverse document frequency\n",
                "   - TF-IDF = (1 + log TF) √ó log(N / DF)\n",
                "   - Balances term importance and rarity\n",
                "\n",
                "2. **IDF Component**\n",
                "   - Rare terms get high IDF (high weight)\n",
                "   - Common terms get low IDF (low weight)\n",
                "   - log(N/DF) smooths the values\n",
                "\n",
                "3. **TF Component**\n",
                "   - Measures term importance within document\n",
                "   - Log normalization prevents domination by high-frequency terms\n",
                "   - 1 + log(freq) is standard\n",
                "\n",
                "4. **Ranking Quality**\n",
                "   - Better than simple TF\n",
                "   - Emphasizes distinctive terms\n",
                "   - Industry standard weighting scheme\n",
                "\n",
                "### Key Insights:\n",
                "\n",
                "**Why TF-IDF Works:**\n",
                "- ‚úì **Discriminative**: Rare terms are more informative\n",
                "- ‚úì **Balanced**: Combines local (TF) and global (IDF) statistics\n",
                "- ‚úì **Robust**: Works well across different domains\n",
                "- ‚úì **Efficient**: Simple to compute and understand\n",
                "\n",
                "**Example:**\n",
                "```\n",
                "Query: \"‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ ‡§π‡§ø‡§Æ‡§æ‡§≤\"\n",
                "\n",
                "- \"‡§∏‡§ó‡§∞‡§Æ‡§æ‡§•‡§æ\" (Sagarmatha/Everest): Rare ‚Üí High IDF ‚Üí High weight\n",
                "- \"‡§π‡§ø‡§Æ‡§æ‡§≤\" (Mountain): More common ‚Üí Lower IDF ‚Üí Lower weight\n",
                "- \"‡§®‡•á‡§™‡§æ‡§≤\" (Nepal): Very common ‚Üí Very low IDF ‚Üí Very low weight\n",
                "\n",
                "Result: Documents about Sagarmatha ranked highest!\n",
                "```\n",
                "\n",
                "### Real-World Usage:\n",
                "- **Google (early versions)**: Used TF-IDF as foundation\n",
                "- **Lucene/Elasticsearch**: Default scoring mechanism\n",
                "- **Text Mining**: Feature extraction for ML\n",
                "- **Document Clustering**: Similarity computation\n",
                "\n",
                "### Next Steps:\n",
                "In the next notebook (`07_language_modeling.ipynb`), we will:\n",
                "- Explore probabilistic IR models\n",
                "- Learn language modeling approach\n",
                "- Compare with TF-IDF\n",
                "- Understand smoothing techniques\n",
                "\n",
                "### Research References:\n",
                "- Salton & Buckley (1988): \"Term-weighting approaches in automatic text retrieval\"\n",
                "- Manning et al., \"Introduction to Information Retrieval\", Chapter 6\n",
                "- Most cited and successful IR weighting scheme\n",
                "- Foundation for modern ranking algorithms (BM25, etc.)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
