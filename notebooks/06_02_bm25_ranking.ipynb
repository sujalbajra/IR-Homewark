{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 6.2: Probabilistic Ranking with BM25\\n\n",
                "\\n\n",
                "This notebook implements the Okapi BM25 ranking algorithm, a state-of-the-art probabilistic model in Information Retrieval. We will implement it from scratch using vanilla Python to understand its components: Term Frequency saturation and Document Length Normalization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import os\n",
                "import glob\n",
                "from collections import defaultdict, Counter"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Preprocess Data\\n\n",
                "We will reuse our dummy Nepali dataset and basic preprocessing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 10 documents.\n"
                    ]
                }
            ],
            "source": [
                "def load_documents(data_dir=\"../data\"):\n",
                "    documents = {}\n",
                "    for filepath in glob.glob(os.path.join(data_dir, \"*.txt\")):\n",
                "        doc_id = os.path.basename(filepath)\n",
                "        with open(filepath, 'r', encoding='utf-8') as f:\n",
                "            documents[doc_id] = f.read()\n",
                "    return documents\n",
                "\n",
                "def preprocess(text):\n",
                "    # Simple whitespace tokenization and normalization for Nepali\n",
                "    return text.lower().split()\n",
                "\n",
                "documents = load_documents()\n",
                "print(f\"Loaded {len(documents)} documents.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. BM25 Theory and Components\\n\n",
                "\\n\n",
                "The BM25 score for a document $D$ given a query $Q$ is calculated as:\\n\n",
                "\\n\n",
                "$$ \\text{score}(D, Q) = \\sum_{q \\in Q} IDF(q) \\cdot \\frac{f(q, D) \\cdot (k_1 + 1)}{f(q, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})} $$\\n\n",
                "\\n\n",
                "Where:\\n\n",
                "- $f(q, D)$ is the term frequency of term $q$ in document $D$\\n\n",
                "- $|D|$ is the length of document $D$ in words\\n\n",
                "- $avgdl$ is the average document length in the collection\\n\n",
                "- $k_1$ controls term frequency saturation (typically 1.2 to 2.0)\\n\n",
                "- $b$ controls length normalization (0 to 1, typically 0.75)\\n\n",
                "- $IDF(q)$ is the Inverse Document Frequency weight"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Implementation of BM25 Indexer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BM25Indexer:\n",
                "    def __init__(self, k1=1.5, b=0.75):\n",
                "        self.k1 = k1\n",
                "        self.b = b\n",
                "        self.doc_lengths = {}\n",
                "        self.avgdl = 0\n",
                "        self.doc_freqs = defaultdict(int)\n",
                "        self.term_freqs = defaultdict(lambda: defaultdict(int)) # term -> doc_id -> count\n",
                "        self.N = 0\n",
                "        self.idf = {}\n",
                "    \n",
                "    def fit(self, documents):\n",
                "        self.N = len(documents)\n",
                "        total_length = 0\n",
                "        \n",
                "        for doc_id, text in documents.items():\n",
                "            tokens = preprocess(text)\n",
                "            length = len(tokens)\n",
                "            self.doc_lengths[doc_id] = length\n",
                "            total_length += length\n",
                "            \n",
                "            # Calculate Term Frequencies per document\n",
                "            counts = Counter(tokens)\n",
                "            for term, count in counts.items():\n",
                "                self.term_freqs[term][doc_id] = count\n",
                "                self.doc_freqs[term] += 1\n",
                "                \n",
                "        self.avgdl = total_length / self.N\n",
                "        self._calc_idf()\n",
                "        \n",
                "    def _calc_idf(self):\n",
                "        # Standard IDF formula: log((N - n + 0.5) / (n + 0.5) + 1)\n",
                "        for term, freq in self.doc_freqs.items():\n",
                "            self.idf[term] = math.log((self.N - freq + 0.5) / (freq + 0.5) + 1)\n",
                "\n",
                "    def score(self, query, doc_id):\n",
                "        score = 0.0\n",
                "        query_terms = preprocess(query)\n",
                "        doc_len = self.doc_lengths.get(doc_id, 0)\n",
                "        \n",
                "        for term in query_terms:\n",
                "            if term not in self.term_freqs:\n",
                "                continue\n",
                "            \n",
                "            idf = self.idf.get(term, 0)\n",
                "            tf = self.term_freqs[term].get(doc_id, 0)\n",
                "            \n",
                "            numerator = tf * (self.k1 + 1)\n",
                "            denominator = tf + self.k1 * (1 - self.b + self.b * (doc_len / self.avgdl))\n",
                "            \n",
                "            score += idf * (numerator / denominator)\n",
                "            \n",
                "        return score\n",
                "    \n",
                "    def search(self, query):\n",
                "        scores = []\n",
                "        for doc_id in self.doc_lengths.keys():\n",
                "            s = self.score(query, doc_id)\n",
                "            if s > 0:\n",
                "                scores.append((doc_id, s))\n",
                "        \n",
                "        return sorted(scores, key=lambda x: x[1], reverse=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Testing the BM25 Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for query: 'नेपालको संविधान'\n",
                        "doc04.txt: 0.4348\n",
                        "doc01.txt: 0.4201\n",
                        "doc08.txt: 0.4188\n",
                        "doc03.txt: 0.3801\n",
                        "doc07.txt: 0.2711\n",
                        "doc02.txt: 0.2574\n",
                        "doc10.txt: 0.2503\n",
                        "doc09.txt: 0.2490\n"
                    ]
                }
            ],
            "source": [
                "bm25 = BM25Indexer(k1=1.5, b=0.75)\n",
                "bm25.fit(documents)\n",
                "\n",
                "# Sample Query\n",
                "query = \"नेपालको संविधान\" # Constitution of Nepal\n",
                "results = bm25.search(query)\n",
                "\n",
                "print(f\"Results for query: '{query}'\")\n",
                "for doc_id, score in results:\n",
                "    print(f\"{doc_id}: {score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Parameter Tuning Analysis\\n\n",
                "Let's see how changing k1 and b affects rankings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- High k1 (2.0) ---\n",
                        "[('doc04.txt', 0.47064720728437776), ('doc01.txt', 0.4516810846315697), ('doc08.txt', 0.4500324129514447)]\n",
                        "\n",
                        "--- Low k1 (0.5) ---\n",
                        "[('doc04.txt', 0.33315166872757707), ('doc01.txt', 0.32827303324143997), ('doc08.txt', 0.32783659668051623)]\n"
                    ]
                }
            ],
            "source": [
                "# Compare High Saturation (k1=2.0) vs Low Saturation (k1=0.5)\n",
                "bm25_high_k = BM25Indexer(k1=2.0, b=0.75)\n",
                "bm25_high_k.fit(documents)\n",
                "\n",
                "bm25_low_k = BM25Indexer(k1=0.5, b=0.75)\n",
                "bm25_low_k.fit(documents)\n",
                "\n",
                "print(\"\\n--- High k1 (2.0) ---\")\n",
                "print(bm25_high_k.search(query)[:3])\n",
                "\n",
                "print(\"\\n--- Low k1 (0.5) ---\")\n",
                "print(bm25_low_k.search(query)[:3])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
