{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 14. PageRank Algorithm\\n\n",
                "\\n\n",
                "PageRank is the famous algorithm used by Google to rank web pages. It treats the web as a graph where pages are nodes and hyperlinks are edges.\\n\n",
                "\\n\n",
                "**Core Idea**: A page is important if important pages link to it.\\n\n",
                "\\n\n",
                "$$ PR(u) = (1-d) + d \\sum_{v \\in B(u)} \\frac{PR(v)}{L(v)} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated 400 links among 60 documents.\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import random\n",
                "\n",
                "# 1. Simulate a Web Graph\\n\n",
                "# We will use our 60 documents (10 original + 50 synthetic)\\n\n",
                "NUM_DOCS = 60\n",
                "doc_ids = [f\"doc{i:03d}\" for i in range(1, NUM_DOCS+1)]\n",
                "\n",
                "# Adjacency Matrix (0 or 1)\n",
                "# We'll generate random links heavily biased within topics\\n\n",
                "links = []\n",
                "for i in range(NUM_DOCS):\n",
                "    # Each doc links to 3-10 other docs\\n\n",
                "    num_outlinks = random.randint(3, 10)\n",
                "    targets = random.sample(range(NUM_DOCS), num_outlinks)\n",
                "    \n",
                "    for t in targets:\n",
                "        if t != i: # No self-loops for simplicity\\n\n",
                "            links.append((i, t))\n",
                "            \n",
                "print(f\"Generated {len(links)} links among {NUM_DOCS} documents.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Power Iteration Implementation\\n\n",
                "\\n\n",
                "We can solve PageRank using the Power Method: repeatedly multiply the rank vector by the transition matrix until convergence."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Converged in 13 iterations.\n",
                        "\n",
                        "Top 10 Ranked Documents:\n",
                        "==============================\n",
                        "1. doc013 (Score: 0.03444)\n",
                        "2. doc057 (Score: 0.03064)\n",
                        "3. doc056 (Score: 0.02619)\n",
                        "4. doc001 (Score: 0.02556)\n",
                        "5. doc005 (Score: 0.02525)\n",
                        "6. doc045 (Score: 0.02480)\n",
                        "7. doc040 (Score: 0.02458)\n",
                        "8. doc026 (Score: 0.02392)\n",
                        "9. doc025 (Score: 0.02363)\n",
                        "10. doc020 (Score: 0.02200)\n"
                    ]
                }
            ],
            "source": [
                "def calculate_pagerank(links, num_pages, damping=0.85, epsilon=1e-6, max_iterations=100):\n",
                "    # 1. Initialize PageRank equally\\n\n",
                "    pagerank = np.ones(num_pages) / num_pages\n",
                "    \n",
                "    # 2. Build Adjacency List & Out-degree\\n\n",
                "    out_degree = [0] * num_pages\n",
                "    in_links = [[] for _ in range(num_pages)]\n",
                "    \n",
                "    for source, target in links:\n",
                "        out_degree[source] += 1\n",
                "        in_links[target].append(source)\n",
                "        \n",
                "    # 3. Iteration\\n\n",
                "    for it in range(max_iterations):\n",
                "        new_pagerank = np.zeros(num_pages)\n",
                "        \n",
                "        # The \"Teleportation\" part (random surfer jumps)\\n\n",
                "        leap_prob = (1 - damping) / num_pages\n",
                "        \n",
                "        for i in range(num_pages):\n",
                "            rank_sum = 0\n",
                "            # Sum of PR(source)/L(source) for all incoming links\\n\n",
                "            for source in in_links[i]:\n",
                "                if out_degree[source] > 0:\n",
                "                    rank_sum += pagerank[source] / out_degree[source]\n",
                "                else:\n",
                "                    # Sink node handling (distribute rank equally)\\n\n",
                "                    rank_sum += pagerank[source] / num_pages\n",
                "            \n",
                "            new_pagerank[i] = leap_prob + damping * rank_sum\n",
                "            \n",
                "        # Check convergence (L1 norm)\\n\n",
                "        diff = np.sum(np.abs(new_pagerank - pagerank))\n",
                "        pagerank = new_pagerank\n",
                "        \n",
                "        if diff < epsilon:\n",
                "            print(f\"Converged in {it+1} iterations.\")\n",
                "            break\n",
                "            \n",
                "    return pagerank\n",
                "\n",
                "pr_scores = calculate_pagerank(links, NUM_DOCS)\n",
                "\n",
                "# Show Top 10 Pages\\n\n",
                "ranked_indices = np.argsort(pr_scores)[::-1]\n",
                "print(\"\\nTop 10 Ranked Documents:\")\n",
                "print(\"=\"*30)\n",
                "for i in range(10):\n",
                "    idx = ranked_indices[i]\n",
                "    print(f\"{i+1}. {doc_ids[idx]} (Score: {pr_scores[idx]:.5f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualization (Optional)\\n\n",
                "If this were a small graph, we could visualize it. Since it's 60 nodes, the Top 10 list is better.\\n\n",
                "\\n\n",
                "## Summary\\n\n",
                "We successfully implemented the Power Iteration method for PageRank manually."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
